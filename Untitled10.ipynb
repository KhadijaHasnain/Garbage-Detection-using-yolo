{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# import os\n",
        "# import sys\n",
        "# from tempfile import NamedTemporaryFile\n",
        "# from urllib.request import urlopen\n",
        "# from urllib.parse import unquote, urlparse\n",
        "# from urllib.error import HTTPError\n",
        "# from zipfile import ZipFile\n",
        "# import tarfile\n",
        "# import shutil\n",
        "\n",
        "# CHUNK_SIZE = 40960\n",
        "# DATA_SOURCE_MAPPING = 'pascalvoc-yolo:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F918769%2F1556326%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240803%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240803T180619Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D60245d936b12665b478461fae2417841ba2c7203275a0ae79659cb349615d122fac7b15d780d8891bb36e299c6bdf680fe6859446ca67e70d8d5432d2125cdeaf545729e8416e98cee7d35e9b170ab7f6cc74a90bfe13132a89fb9d1e010d24a968018b5af2820483069c50f9e19a704c76552339d4d6b9e706cd97f54082ed42e35db0153b33745f56f4ba8add1879563830b759076dc443bdaf5059a6d9b14ac3fffea278ebe72b2599b5f1aa4ac69e61b10489dd613fa15191ff298552939ad0b28066478f9d2aea9cb4559e8b32b431070c89b1d3ea223d49a482bffa1dc5916f86a5a8d4457e1b12276d4f19e028cfbc32bff990ed382347814dff79301'\n",
        "\n",
        "# KAGGLE_INPUT_PATH='/kaggle/input'\n",
        "# KAGGLE_WORKING_PATH='/kaggle/working'\n",
        "# KAGGLE_SYMLINK='kaggle'\n",
        "\n",
        "# !umount /kaggle/input/ 2> /dev/null\n",
        "# shutil.rmtree('/kaggle/input', ignore_errors=True)\n",
        "# os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)\n",
        "# os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)\n",
        "\n",
        "# try:\n",
        "#   os.symlink(KAGGLE_INPUT_PATH, os.path.join(\"..\", 'input'), target_is_directory=True)\n",
        "# except FileExistsError:\n",
        "#   pass\n",
        "# try:\n",
        "#   os.symlink(KAGGLE_WORKING_PATH, os.path.join(\"..\", 'working'), target_is_directory=True)\n",
        "# except FileExistsError:\n",
        "#   pass\n",
        "\n",
        "# for data_source_mapping in DATA_SOURCE_MAPPING.split(','):\n",
        "#     directory, download_url_encoded = data_source_mapping.split(':')\n",
        "#     download_url = unquote(download_url_encoded)\n",
        "#     filename = urlparse(download_url).path\n",
        "#     destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)\n",
        "#     try:\n",
        "#         with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:\n",
        "#             total_length = fileres.headers['content-length']\n",
        "#             print(f'Downloading {directory}, {total_length} bytes compressed')\n",
        "#             dl = 0\n",
        "#             data = fileres.read(CHUNK_SIZE)\n",
        "#             while len(data) > 0:\n",
        "#                 dl += len(data)\n",
        "#                 tfile.write(data)\n",
        "#                 done = int(50 * dl / int(total_length))\n",
        "#                 sys.stdout.write(f\"\\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded\")\n",
        "#                 sys.stdout.flush()\n",
        "#                 data = fileres.read(CHUNK_SIZE)\n",
        "#             if filename.endswith('.zip'):\n",
        "#               with ZipFile(tfile) as zfile:\n",
        "#                 zfile.extractall(destination_path)\n",
        "#             else:\n",
        "#               with tarfile.open(tfile.name) as tarfile:\n",
        "#                 tarfile.extractall(destination_path)\n",
        "#             print(f'\\nDownloaded and uncompressed: {directory}')\n",
        "#     except HTTPError as e:\n",
        "#         print(f'Failed to load (likely expired) {download_url} to path {destination_path}')\n",
        "#         continue\n",
        "#     except OSError as e:\n",
        "#         print(f'Failed to load {download_url} to path {destination_path}')\n",
        "#         continue\n",
        "\n",
        "# print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "WOmORtUQkq4E"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install wandb"
      ],
      "metadata": {
        "id": "jrfeB5wtBC0B"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from PIL import Image, ImageFile\n",
        "from collections import Counter\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "import wandb  # Import wandb\n",
        "from transformers import BertTokenizer"
      ],
      "metadata": {
        "id": "hSixTi4uBIfN"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Login with the API KEY\n",
        "wandb.login(key=\"ab35ea8191eba471c2b58a844910531625b00550\")\n",
        "\n",
        "# Initialize wandb\n",
        "wandb.init(project=\"Untitled10\", entity=\"mblogge785-work\")  # Replace with your wandb username"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        },
        "id": "sY8DenwZBPCS",
        "outputId": "ad98c564-0881-45a3-ea09-66eb5ab11b7b"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmblogge785\u001b[0m (\u001b[33mmblogge785-work\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.17.5"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20240805_144235-2vf7sbvu</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/mblogge785-work/Untitled10/runs/2vf7sbvu' target=\"_blank\">vocal-sun-19</a></strong> to <a href='https://wandb.ai/mblogge785-work/Untitled10' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/mblogge785-work/Untitled10' target=\"_blank\">https://wandb.ai/mblogge785-work/Untitled10</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/mblogge785-work/Untitled10/runs/2vf7sbvu' target=\"_blank\">https://wandb.ai/mblogge785-work/Untitled10/runs/2vf7sbvu</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/mblogge785-work/Untitled10/runs/2vf7sbvu?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
            ],
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x7879aacf0400>"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
      ],
      "metadata": {
        "id": "j-EQyFuGpdiW"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define configuration for YOLOv3\n",
        "config = [\n",
        "    (32, 3, 1),\n",
        "    (128, 3, 1),\n",
        "    (64, 3, 2),\n",
        "    [\"list\", 1],\n",
        "    (128, 3, 2),\n",
        "    [\"list\", 2],\n",
        "    (256, 3, 2),\n",
        "    [\"list\", 8],\n",
        "    (512, 3, 2),\n",
        "    [\"list\", 8],\n",
        "    (1024, 3, 2),\n",
        "    [\"list\", 4],\n",
        "    (512, 1, 1),\n",
        "    (1024, 3, 1),\n",
        "    \"sp\",\n",
        "    (256, 1, 1),\n",
        "    \"up\",\n",
        "    (256, 1, 1),\n",
        "    (512, 3, 1),\n",
        "    \"sp\",\n",
        "    (128, 1, 1),\n",
        "    \"up\",\n",
        "    (128, 1, 1),\n",
        "    (256, 3, 1),\n",
        "    \"sp\",\n",
        "]"
      ],
      "metadata": {
        "id": "PFiBWZrpDg1w"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define CNN block\n",
        "class CNN_Block(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, bn_act=True, **kwargs):\n",
        "        super(CNN_Block, self).__init__()\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, bias=not bn_act, **kwargs)\n",
        "        self.bn = nn.BatchNorm2d(out_channels)\n",
        "        self.leaky = nn.LeakyReLU(0.1)\n",
        "        self.use_bn_act = bn_act\n",
        "\n",
        "    def forward(self, x):\n",
        "        if self.use_bn_act:\n",
        "            return self.leaky(self.bn(self.conv(x)))\n",
        "        else:\n",
        "            return self.conv(x)"
      ],
      "metadata": {
        "id": "xgUPQ25bD73i"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define Residual block\n",
        "class Residual_Block(nn.Module):\n",
        "    def __init__(self, channels, use_residual=True, num_repeats=1):\n",
        "        super(Residual_Block, self).__init__()\n",
        "        self.layers = nn.ModuleList()\n",
        "\n",
        "        for repeat in range(num_repeats):\n",
        "            self.layers += [\n",
        "                nn.Sequential(\n",
        "                    CNN_Block(channels, channels//2, kernel_size=1),\n",
        "                    CNN_Block(channels//2, channels, kernel_size=3, padding=1)\n",
        "                )\n",
        "            ]\n",
        "\n",
        "        self.use_residual = use_residual\n",
        "        self.num_repeats = num_repeats\n",
        "\n",
        "    def forward(self, x):\n",
        "        for layer in self.layers:\n",
        "            if self.use_residual:\n",
        "                x = x + layer(x)\n",
        "            else:\n",
        "                x = layer(x)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "30BGaEvUEAG9"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define Prediction Scale\n",
        "class Prediction_Scale(nn.Module):\n",
        "    def __init__(self, in_channels, NumClasses):\n",
        "        super(Prediction_Scale, self).__init__()\n",
        "        self.pred = nn.Sequential(\n",
        "            CNN_Block(in_channels, 2 * in_channels, kernel_size=3, padding=1),\n",
        "            CNN_Block(2 * in_channels, (NumClasses + 5) * 3, bn_act=False, kernel_size=1),\n",
        "        )\n",
        "        self.NumClasses = NumClasses\n",
        "\n",
        "    def forward(self, x):\n",
        "        return (\n",
        "            self.pred(x)\n",
        "            .reshape(x.shape[0], 3, self.NumClasses + 5, x.shape[2], x.shape[3])\n",
        "            .permute(0, 1, 3, 4, 2)\n",
        "        )"
      ],
      "metadata": {
        "id": "WmWG3n0TEKR-"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class YOLOv3(nn.Module):\n",
        "  def __init__(self, in_channels=3, NumClasses=20):\n",
        "    super(YOLOv3, self).__init__()\n",
        "    self.NumClasses = NumClasses\n",
        "    self.in_channels = in_channels\n",
        "    self.layers = self._create_conv_layers()\n",
        "\n",
        "  def forward(self, x):\n",
        "    outputs = []\n",
        "    route_connections = []\n",
        "\n",
        "    for layer in self.layers:\n",
        "      if isinstance(layer, Prediction_Scale):\n",
        "        outputs.append(layer(x))\n",
        "        continue\n",
        "\n",
        "      x = layer(x)\n",
        "\n",
        "      if isinstance(layer, Residual_Block) and layer.num_repeats == 8:\n",
        "        route_connections.append(x)\n",
        "\n",
        "      elif isinstance(layer, nn.Upsample):\n",
        "        x = torch.cat([x, route_connections[-1]], dim=1)\n",
        "        route_connections.pop()\n",
        "\n",
        "    return outputs\n",
        "\n",
        "  def _create_conv_layers(self):\n",
        "    layers = nn.ModuleList()\n",
        "    in_channels = self.in_channels\n",
        "\n",
        "    for module in config:\n",
        "      if isinstance(module, tuple):\n",
        "        out_channels, kernel_size, stride = module\n",
        "        layers.append(CNN_Block(\n",
        "            in_channels,\n",
        "            out_channels,\n",
        "            kernel_size=kernel_size,\n",
        "            stride=stride,\n",
        "            padding=1 if kernel_size == 3 else 0\n",
        "        ))\n",
        "        in_channels = out_channels\n",
        "\n",
        "      elif isinstance(module, list):\n",
        "        num_repeats = module[1]\n",
        "        layers.append(Residual_Block(in_channels, num_repeats=num_repeats))\n",
        "\n",
        "      elif isinstance(module, str):\n",
        "        if module == \"sp\":\n",
        "          layers += [\n",
        "              Residual_Block(in_channels, use_residual=False, num_repeats=1),\n",
        "              CNN_Block(in_channels, in_channels//2, kernel_size=1),\n",
        "              Prediction_Scale(in_channels//2, NumClasses = self.NumClasses)\n",
        "          ]\n",
        "          in_channels = in_channels // 2\n",
        "\n",
        "        elif module == \"up\":\n",
        "          layers.append(nn.Upsample(scale_factor=2))\n",
        "          in_channels = in_channels * 3\n",
        "\n",
        "    return layers"
      ],
      "metadata": {
        "id": "xkCgT8d4EaWa"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model hyperparameters\n",
        "INPUT_DIM = tokenizer.vocab_size\n",
        "OUTPUT_DIM = tokenizer.vocab_size\n",
        "ENC_EMB_DIM = 512\n",
        "DEC_EMB_DIM = 512\n",
        "HID_DIM = 1024\n",
        "N_LAYERS = 2\n",
        "ENC_DROPOUT = 0.3\n",
        "DEC_DROPOUT = 0.3\n",
        "\n",
        "wandb.config.update({\n",
        "    \"learning_rate\": 1e-3,\n",
        "    \"epochs\": 30,\n",
        "    \"batch_size\": 64,\n",
        "    \"encoder_embedding_dim\": ENC_EMB_DIM,\n",
        "    \"decoder_embedding_dim\": DEC_EMB_DIM,\n",
        "    \"hidden_dim\": HID_DIM,\n",
        "    \"num_layers\": N_LAYERS,\n",
        "    \"encoder_dropout\": ENC_DROPOUT,\n",
        "    \"decoder_dropout\": DEC_DROPOUT\n",
        "})\n",
        "optimizer = optim.Adam(model.parameters(), lr=wandb.config.learning_rate)\n",
        "TRG_PAD_IDX = tokenizer.pad_token_id\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=TRG_PAD_IDX)"
      ],
      "metadata": {
        "id": "lwpV0sCyuvF-"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NumClasses = 20\n",
        "ImageSize = 416\n",
        "model = YOLOv3(NumClasses=NumClasses)\n",
        "x = torch.randn((2, 3, ImageSize, ImageSize))\n",
        "out = model(x)\n",
        "assert model(x)[0].shape == (2, 3, ImageSize//32, ImageSize//32, NumClasses + 5)\n",
        "assert model(x)[1].shape == (2, 3, ImageSize//16, ImageSize//16, NumClasses + 5)\n",
        "assert model(x)[2].shape == (2, 3, ImageSize//8, ImageSize//8, NumClasses + 5)\n",
        "print(\"Success!\")"
      ],
      "metadata": {
        "id": "iVML2Ku2EnO2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ea572df-bba2-4a63-dc6a-bbfbeeb371af"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Success!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define utility functions\n",
        "def WeidthHeight(boxa, boxb):\n",
        "    intersection = torch.min(boxa[..., 0], boxb[..., 0]) * torch.min(\n",
        "        boxa[..., 1], boxb[..., 1]\n",
        "    )\n",
        "    union = (\n",
        "        boxa[..., 0] * boxa[..., 1] + boxb[..., 0] * boxb[..., 1] - intersection\n",
        "    )\n",
        "    return intersection / union\n",
        "\n",
        "def non_max_suppression(boxx, iou_threshold, threshold, box_format=\"corners\"):\n",
        "    assert type(boxx) == list\n",
        "\n",
        "    boxx = [box for box in boxx if box[1] > threshold]\n",
        "    boxx = sorted(boxx, key=lambda x: x[1], reverse=True)\n",
        "    boxx_after_nms = []\n",
        "\n",
        "    while boxx:\n",
        "        chosen_box = boxx.pop(0)\n",
        "\n",
        "        boxx = [\n",
        "            box\n",
        "            for box in boxx\n",
        "            if box[0] != chosen_box[0]\n",
        "            or InterctionOverUnion(\n",
        "                torch.tensor(chosen_box[2:]),\n",
        "                torch.tensor(box[2:]),\n",
        "                box_format=box_format,\n",
        "            )\n",
        "            < iou_threshold\n",
        "        ]\n",
        "\n",
        "        boxx_after_nms.append(chosen_box)\n",
        "\n",
        "    return boxx_after_nms\n",
        "\n",
        "def InterctionOverUnion(PredsBox, lableBox, box_format=\"midpoint\"):\n",
        "    if box_format == \"midpoint\":\n",
        "        box1_a1 = PredsBox[..., 0:1] - PredsBox[..., 2:3] / 2\n",
        "        box1_b1 = PredsBox[..., 1:2] - PredsBox[..., 3:4] / 2\n",
        "        box1_a2 = PredsBox[..., 0:1] + PredsBox[..., 2:3] / 2\n",
        "        box1_b2 = PredsBox[..., 1:2] + PredsBox[..., 3:4] / 2\n",
        "        box2_a1 = lableBox[..., 0:1] - lableBox[..., 2:3] / 2\n",
        "        box2_y1 = lableBox[..., 1:2] - lableBox[..., 3:4] / 2\n",
        "        box2_a2 = lableBox[..., 0:1] + lableBox[..., 2:3] / 2\n",
        "        box2_y2 = lableBox[..., 1:2] + lableBox[..., 3:4] / 2\n",
        "\n",
        "    if box_format == \"corners\":\n",
        "        box1_a1 = PredsBox[..., 0:1]\n",
        "        box1_b1 = PredsBox[..., 1:2]\n",
        "        box1_a2 = PredsBox[..., 2:3]\n",
        "        box1_b2 = PredsBox[..., 3:4]\n",
        "        box2_a1 = lableBox[..., 0:1]\n",
        "        box2_y1 = lableBox[..., 1:2]\n",
        "        box2_a2 = lableBox[..., 2:3]\n",
        "        box2_y2 = lableBox[..., 3:4]\n",
        "\n",
        "    x1 = torch.max(box1_a1, box2_a1)\n",
        "    y1 = torch.max(box1_b1, box2_y1)\n",
        "    x2 = torch.min(box1_a2, box2_a2)\n",
        "    y2 = torch.min(box1_b2, box2_y2)\n",
        "    intersection = torch.clamp(x2 - x1, min=0) * torch.clamp(y2 - y1, min=0)\n",
        "    box1_area = (box1_a2 - box1_a1) * (box1_b2 - box1_b1)\n",
        "    box2_area = (box2_a2 - box2_a1) * (box2_y2 - box2_y1)\n",
        "    iou = intersection / (box1_area + box2_area - intersection)\n",
        "\n",
        "    return iou"
      ],
      "metadata": {
        "id": "uuvFaoFbEwfR"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#added own\n",
        "# allows PIL to load images even if they are truncated or incomplete\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True"
      ],
      "metadata": {
        "id": "nOAqW-MGFJXE"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#added own imp\n",
        "class YOLODataset(Dataset):\n",
        "  def __init__(self, csv_file, ImgDir, LableDir, anchors,\n",
        "               ImageSize=416, sp=[13,26,52], cp=20, transform=None):\n",
        "    self.annotations = pd.read_csv(csv_file)\n",
        "    self.ImgDir = ImgDir\n",
        "    self.LableDir = LableDir\n",
        "    self.transform = transform\n",
        "    self.sp = sp\n",
        "\n",
        "    self.anchors = torch.tensor(anchors[0] + anchors[1] + anchors[2]) # For all 3 scales\n",
        "    self.num_anchors = self.anchors.shape[0]\n",
        "    self.num_anchors_per_scale = self.num_anchors // 3\n",
        "\n",
        "    self.cp = cp\n",
        "\n",
        "    self.ignore_iou_thresh = 0.5\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.annotations)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    label_path = os.path.join(self.LableDir, self.annotations.iloc[index, 1])\n",
        "    boxx = np.roll(np.loadtxt(fname=label_path, delimiter=\" \", ndmin=2), 4, axis=1).tolist() # np.roll with shift 4 on axis 1: [class, x, y, w, h] --> [x, y, w, h, class]\n",
        "\n",
        "    img_path = os.path.join(self.ImgDir, self.annotations.iloc[index, 0])\n",
        "    image = Image.open(img_path)\n",
        "\n",
        "    if self.transform:\n",
        "      image = self.transform(image)\n",
        "\n",
        "    targets = [torch.zeros((self.num_anchors // 3, sp, sp, 6)) for sp in self.sp] # 6 because objectness score, bounding box coordinates (x, y, w, h), class label\n",
        "\n",
        "    for box in boxx:\n",
        "      iou_anchors = WeidthHeight(torch.tensor(box[2:4]), self.anchors) # IOU from height and width\n",
        "      anchor_indices = iou_anchors.argsort(descending=True, dim=0) # Sorting sucht that the first is the best anchor\n",
        "\n",
        "      x, y, width, height, class_label = box\n",
        "      has_anchor = [False, False, False] # Make sure there is an anchor for each of three scales for each bounding box\n",
        "\n",
        "      for anchor_idx in anchor_indices:\n",
        "        scale_idx = anchor_idx // self.num_anchors_per_scale # scale_idx is either 0,1,2: 0-->13x13, 1:-->26x26, 2:-->52x52\n",
        "        anchor_on_scale = anchor_idx % self.num_anchors_per_scale # In each scale, choosing the anchor thats either 0,1,2\n",
        "\n",
        "        sp = self.sp[scale_idx]\n",
        "        i, j = int(sp*y), int(sp*x) # x=0.5, sp=13 --> int(6.5) = 6 | i=y cell, j=x cell\n",
        "        anchor_taken = targets[scale_idx][anchor_on_scale, i, j, 0]\n",
        "\n",
        "        if not anchor_taken and not has_anchor[scale_idx]:\n",
        "          targets[scale_idx][anchor_on_scale, i, j, 0] = 1\n",
        "          x_cell, y_cell = sp*x - j, sp*y - i # 6.5 - 6 = 0.5 such that they are between [0,1]\n",
        "          width_cell, height_cell = (\n",
        "              width*sp, # sp=13, width=0.5, 6.5\n",
        "              height*sp\n",
        "          )\n",
        "\n",
        "          box_coordinates = torch.tensor([x_cell, y_cell, width_cell, height_cell])\n",
        "\n",
        "          targets[scale_idx][anchor_on_scale, i, j, 1:5] = box_coordinates\n",
        "          targets[scale_idx][anchor_on_scale, i, j, 5] = int(class_label)\n",
        "          has_anchor[scale_idx] = True\n",
        "\n",
        "        # Even if the same grid shares another anchor having iou>ignore_iou_thresh then,\n",
        "        elif not anchor_taken and iou_anchors[anchor_idx] > self.ignore_iou_thresh:\n",
        "          targets[scale_idx][anchor_on_scale, i, j, 0] = -1 # ignore this prediction\n",
        "\n",
        "    return image, tuple(targets)\n",
        "\n",
        "    # Define dataset\n",
        "# class YOLODataset(Dataset):\n",
        "#     def __init__(self, csv_file, transform=None):\n",
        "#         self.data_frame = pd.read_csv(csv_file)\n",
        "#         self.transform = transform\n",
        "\n",
        "#     def __len__(self):\n",
        "#         return len(self.data_frame)\n",
        "\n",
        "#     def __getitem__(self, idx):\n",
        "#         img_name = os.path.join(self.data_frame.iloc[idx, 0])\n",
        "#         image = Image.open(img_name)\n",
        "#         boxes = self.data_frame.iloc[idx, 1:]\n",
        "\n",
        "#         if self.transform:\n",
        "#             image = self.transform(image)\n",
        "\n",
        "#         return image, boxes\n"
      ],
      "metadata": {
        "id": "mmYZNNBFGQuI"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision.transforms as transforms\n",
        "transform = transforms.Compose([transforms.Resize((416, 416)), transforms.ToTensor()])"
      ],
      "metadata": {
        "id": "Zj_rMGdgkSMV"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#added own imp\n",
        "def get_loaders(train_csv_path, test_csv_path):\n",
        "\n",
        "    train_dataset = YOLODataset(\n",
        "        train_csv_path,\n",
        "        transform=transform,\n",
        "        sp=[ImageSize // 32, ImageSize // 16, ImageSize // 8],\n",
        "        ImgDir=DirImage,\n",
        "        LableDir=DirLable,\n",
        "        anchors=ANCHORS,\n",
        "    )\n",
        "    test_dataset = YOLODataset(\n",
        "        test_csv_path,\n",
        "        transform=transform,\n",
        "        sp=[ImageSize // 32, ImageSize // 16, ImageSize // 8],\n",
        "        ImgDir=DirImage,\n",
        "        LableDir=DirLable,\n",
        "        anchors=ANCHORS,\n",
        "    )\n",
        "    train_loader = DataLoader(\n",
        "        dataset=train_dataset,\n",
        "        batch_size=SizeOfBatch,\n",
        "        shuffle=True,\n",
        "        drop_last=False,\n",
        "    )\n",
        "    test_loader = DataLoader(\n",
        "        dataset=test_dataset,\n",
        "        batch_size=SizeOfBatch,\n",
        "        shuffle=False,\n",
        "        drop_last=False,\n",
        "    )\n",
        "\n",
        "    return train_loader, test_loader\n",
        "\n",
        "#     # Define data loaders\n",
        "# def get_loaders(csv_file, batch_size, num_workers=0, shuffle=True):\n",
        "#     transform = transforms.Compose([\n",
        "#         transforms.ToTensor(),\n",
        "#         transforms.Resize((416, 416)),\n",
        "#     ])\n",
        "\n",
        "#     dataset = YOLODataset(csv_file=csv_file, transform=transform)\n",
        "#     return DataLoader(dataset, batch_size=batch_size, shuffle=shuffle, num_workers=num_workers)"
      ],
      "metadata": {
        "id": "KrFm4bATG-Sm"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mean_average_precision(\n",
        "    pred_boxes, true_boxes, iou_threshold=0.5, box_format=\"midpoint\", NumClasses=4\n",
        "):\n",
        "\n",
        "    # list storing all AP for respective classes\n",
        "    average_precisions = []\n",
        "\n",
        "    # used for numerical stability later on\n",
        "    epsilon = 1e-6\n",
        "\n",
        "    for c in range(NumClasses):\n",
        "        detections = []\n",
        "        ground_truths = []\n",
        "\n",
        "        for detection in pred_boxes:\n",
        "            if detection[1] == c:\n",
        "                detections.append(detection)\n",
        "\n",
        "        for true_box in true_boxes:\n",
        "            if true_box[1] == c:\n",
        "                ground_truths.append(true_box)\n",
        "\n",
        "        amount_boxx = Counter([gt[0] for gt in ground_truths])\n",
        "\n",
        "        for key, val in amount_boxx.items():\n",
        "            amount_boxx[key] = torch.zeros(val)\n",
        "\n",
        "        # sort by box probabilities which is index 2\n",
        "        detections.sort(key=lambda x: x[2], reverse=True)\n",
        "        TP = torch.zeros((len(detections)))\n",
        "        FP = torch.zeros((len(detections)))\n",
        "        total_true_boxx = len(ground_truths)\n",
        "\n",
        "        # If none exists for this class then we can safely skip\n",
        "        if total_true_boxx == 0:\n",
        "            continue\n",
        "\n",
        "        for detection_idx, detection in enumerate(detections):\n",
        "            ground_truth_img = [\n",
        "                bbox for bbox in ground_truths if bbox[0] == detection[0]\n",
        "            ]\n",
        "\n",
        "            num_gts = len(ground_truth_img)\n",
        "            best_iou = 0\n",
        "\n",
        "            for idx, gt in enumerate(ground_truth_img):\n",
        "                iou = InterctionOverUnion(\n",
        "                    torch.tensor(detection[3:]),\n",
        "                    torch.tensor(gt[3:]),\n",
        "                    box_format=box_format,\n",
        "                )\n",
        "\n",
        "                if iou > best_iou:\n",
        "                    best_iou = iou\n",
        "                    best_gt_idx = idx\n",
        "\n",
        "            if best_iou > iou_threshold:\n",
        "                # only detect ground truth detection once\n",
        "                if amount_boxx[detection[0]][best_gt_idx] == 0:\n",
        "                    # true positive and add this bounding box to seen\n",
        "                    TP[detection_idx] = 1\n",
        "                    amount_boxx[detection[0]][best_gt_idx] = 1\n",
        "                else:\n",
        "                    FP[detection_idx] = 1\n",
        "\n",
        "            # if IOU is lower then the detection is a false positive\n",
        "            else:\n",
        "                FP[detection_idx] = 1\n",
        "\n",
        "        TP_cumsum = torch.cumsum(TP, dim=0)\n",
        "        FP_cumsum = torch.cumsum(FP, dim=0)\n",
        "        recalls = TP_cumsum / (total_true_boxx + epsilon)\n",
        "        precisions = TP_cumsum / (TP_cumsum + FP_cumsum + epsilon)\n",
        "        precisions = torch.cat((torch.tensor([1]), precisions))\n",
        "        recalls = torch.cat((torch.tensor([0]), recalls))\n",
        "        # torch.trapz for numerical integration\n",
        "        average_precisions.append(torch.trapz(precisions, recalls))\n",
        "\n",
        "    return sum(average_precisions) / len(average_precisions)"
      ],
      "metadata": {
        "id": "XqvAW5UoizM3"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#added own\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "WorkersNo = 4\n",
        "SizeOfBatch = 32\n",
        "ImageSize = 416\n",
        "ClassesNo = 20\n",
        "RateOfLearning = 1e-5\n",
        "epochsno = 150\n",
        "ThresholdConf = 0.8\n",
        "ThreshMap = 0.5\n",
        "ThreshNms = 0.45\n",
        "sp = [ImageSize // 32, ImageSize // 16, ImageSize // 8]\n",
        "\n",
        "DirImage = \"/kaggle/input/pascalvoc-yolo/images\"\n",
        "DirLable = \"/kaggle/input/pascalvoc-yolo/labels\"\n",
        "\n",
        "ANCHORS = [\n",
        "    [(0.28, 0.22), (0.38, 0.48), (0.9, 0.78)],\n",
        "    [(0.07, 0.15), (0.15, 0.11), (0.14, 0.29)],\n",
        "    [(0.02, 0.03), (0.04, 0.07), (0.08, 0.06)],\n",
        "]\n",
        "\n",
        "\n",
        "AllClacess = [\n",
        "    \"aeroplane\",\n",
        "    \"bicycle\",\n",
        "    \"bird\",\n",
        "    \"boat\",\n",
        "    \"bottle\",\n",
        "    \"bus\",\n",
        "    \"car\",\n",
        "    \"cat\",\n",
        "    \"chair\",\n",
        "    \"cow\",\n",
        "    \"diningtable\",\n",
        "    \"dog\",\n",
        "    \"horse\",\n",
        "    \"motorbike\",\n",
        "    \"person\",\n",
        "    \"pottedplant\",\n",
        "    \"sheep\",\n",
        "    \"sofa\",\n",
        "    \"train\",\n",
        "    \"tvmonitor\"\n",
        "]"
      ],
      "metadata": {
        "id": "lRTkY-6e6Cb7"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_evaluation_boxx(\n",
        "    loader,\n",
        "    model,\n",
        "    iou_threshold,\n",
        "    anchors,\n",
        "    threshold,\n",
        "    box_format=\"midpoint\"\n",
        "):\n",
        "\n",
        "    # make sure model is in eval before get boxx\n",
        "    model.eval()\n",
        "    train_idx = 0\n",
        "    all_pred_boxes = []\n",
        "    all_true_boxes = []\n",
        "    for batch_idx, (x, labels) in enumerate(loader):\n",
        "        x = x.float().to(DEVICE)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            predictions = model(x)\n",
        "\n",
        "        batch_size = x.shape[0]\n",
        "        boxx = [[] for _ in range(batch_size)]\n",
        "        for i in range(3):\n",
        "            sp = predictions[i].shape[2] # grid cell size for each predictions\n",
        "            anchor = torch.tensor([*anchors[i]]).to(DEVICE) * sp # anchor for each grid, prediction type\n",
        "            boxes_scale_i = cells_to_boxx( # get boxx for each image in the batch\n",
        "                predictions[i], anchor, sp=sp, is_preds=True\n",
        "            )\n",
        "            for idx, (box) in enumerate(boxes_scale_i): # for each image, append the bbox to corr. boxx[idx]\n",
        "                boxx[idx] += box\n",
        "\n",
        "        # we just want one bbox for each label, not one for each scale\n",
        "        true_boxx = cells_to_boxx(\n",
        "            labels[2], anchor, sp=sp, is_preds=False\n",
        "        )\n",
        "\n",
        "        for idx in range(batch_size):\n",
        "            nms_boxes = non_max_suppression(\n",
        "                boxx[idx],\n",
        "                iou_threshold=iou_threshold,\n",
        "                threshold=threshold,\n",
        "                box_format=box_format,\n",
        "            )\n",
        "\n",
        "            for nms_box in nms_boxes:\n",
        "                all_pred_boxes.append([train_idx] + nms_box)\n",
        "\n",
        "            for box in true_boxx[idx]:\n",
        "                if box[1] > threshold:\n",
        "                    all_true_boxes.append([train_idx] + box)\n",
        "\n",
        "            train_idx += 1\n",
        "\n",
        "    model.train()\n",
        "    return all_pred_boxes, all_true_boxes"
      ],
      "metadata": {
        "id": "drSirQw4jJNQ"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#added own imp\n",
        "def cells_to_boxx(predictions, anchors, sp, is_preds=True):\n",
        "\n",
        "    SizeOfBatch = predictions.shape[0]\n",
        "    num_anchors = len(anchors)\n",
        "    box_predictions = predictions[..., 1:5]\n",
        "    if is_preds:\n",
        "        anchors = anchors.reshape(1, len(anchors), 1, 1, 2)\n",
        "        box_predictions[..., 0:2] = torch.sigmoid(box_predictions[..., 0:2])\n",
        "        box_predictions[..., 2:] = torch.exp(box_predictions[..., 2:]) * anchors\n",
        "        scores = torch.sigmoid(predictions[..., 0:1])\n",
        "        best_class = torch.argmax(predictions[..., 5:], dim=-1).unsqueeze(-1)\n",
        "    else:\n",
        "        scores = predictions[..., 0:1]\n",
        "        best_class = predictions[..., 5:6]\n",
        "\n",
        "    cell_indices = (\n",
        "        torch.arange(sp)\n",
        "        .repeat(predictions.shape[0], 3, sp, 1)\n",
        "        .unsqueeze(-1)\n",
        "        .to(predictions.DEVICE)\n",
        "    )\n",
        "    x = 1 / sp * (box_predictions[..., 0:1] + cell_indices)\n",
        "    y = 1 / sp * (box_predictions[..., 1:2] + cell_indices.permute(0, 1, 3, 2, 4))\n",
        "    w_h = 1 / sp * box_predictions[..., 2:4]\n",
        "    converted_boxx = torch.cat((best_class, scores, x, y, w_h), dim=-1).reshape(SizeOfBatch, num_anchors * sp * sp, 6)\n",
        "    return converted_boxx.tolist()\n",
        "\n",
        "# Define bounding box conversion\n",
        "# def cells_to_boxx(prediction, anchors, img_size=416):\n",
        "#     grid_size = prediction.shape[2]\n",
        "#     box_x, box_y = torch.meshgrid([torch.arange(grid_size)] * 2, indexing='ij')\n",
        "#     box_x = box_x.to(prediction.DEVICE)\n",
        "#     box_y = box_y.to(prediction.DEVICE)\n",
        "\n",
        "#     prediction = prediction.reshape(-1, grid_size, grid_size, 3, 5 + 20)\n",
        "#     prediction[..., :2] = torch.sigmoid(prediction[..., :2]) + torch.cat([box_x.unsqueeze(-1), box_y.unsqueeze(-1)], dim=-1).float()\n",
        "#     prediction[..., 2:4] = torch.exp(prediction[..., 2:4]) * torch.tensor(anchors).to(prediction.DEVICE).unsqueeze(0).unsqueeze(0)\n",
        "#     prediction[..., :4] *= img_size\n",
        "\n",
        "#     return prediction"
      ],
      "metadata": {
        "id": "9sWupTfzIDnn"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#added own imp\n",
        "class YoloLoss(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(YoloLoss, self).__init__()\n",
        "    self.mse = nn.MSELoss() # For bounding box loss\n",
        "    self.bce = nn.BCEWithLogitsLoss() # For multi-label prediction: Binary cross entropy\n",
        "    self.entropy = nn.CrossEntropyLoss() # For classification\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    # Constants for significance of obj, or no obj.\n",
        "    self.lambda_class = 1\n",
        "    self.lambda_noobj = 10\n",
        "    self.lambda_obj = 1\n",
        "    self.lambda_box = 10\n",
        "\n",
        "  def forward(self, predictions, target, anchors):\n",
        "    obj = target[..., 0] == 1\n",
        "    noobj = target[..., 0] == 0\n",
        "\n",
        "    no_object_loss = self.bce(\n",
        "        (predictions[..., 0:1][noobj]), (target[..., 0:1][noobj])\n",
        "    )\n",
        "\n",
        "    anchors = anchors.reshape(1,3,1,1,2) # Anchors initial shape 3x2 --> 3 anchor boxes each of certain hxw (2)\n",
        "\n",
        "    # box_preds = [..., sigmoid(x), sigmoid(y), [p_w * exp(t_w)], [p_h * exp(t_h)], ...]\n",
        "    box_preds = torch.cat([self.sigmoid(predictions[..., 1:3]), torch.exp(predictions[..., 3:5]) * anchors], dim=-1)\n",
        "\n",
        "    # iou between predicted box and target box\n",
        "    ious = InterctionOverUnion(box_preds[obj], target[..., 1:5][obj]).detach()\n",
        "\n",
        "    object_loss = self.bce(\n",
        "        (predictions[..., 0:1][obj]), (ious * target[..., 0:1][obj]) # target * iou because only intersected part object loss calc\n",
        "    )\n",
        "\n",
        "    predictions[..., 1:3] = self.sigmoid(predictions[..., 1:3]) # x, y to be between [0,1]\n",
        "    target[..., 3:5] = torch.log(\n",
        "        (1e-6 + target[..., 3:5] / anchors)\n",
        "    ) # Exponential of hxw (taking log because opp. of exp)\n",
        "\n",
        "    box_loss = self.mse(predictions[..., 1:5][obj], target[..., 1:5][obj])\n",
        "\n",
        "    class_loss = self.entropy(\n",
        "        (predictions[..., 5:][obj]), (target[..., 5][obj].long())\n",
        "    )\n",
        "\n",
        "    return(\n",
        "        self.lambda_box * box_loss\n",
        "        + self.lambda_obj * object_loss\n",
        "        + self.lambda_noobj * no_object_loss\n",
        "        + self.lambda_class * class_loss\n",
        "    )\n",
        "\n",
        "# Define loss function for YOLOv3\n",
        "# class YoloLoss(nn.Module):\n",
        "#     def __init__(self, anchors, num_classes):\n",
        "#         super(YoloLoss, self).__init__()\n",
        "#         self.anchors = anchors\n",
        "#         self.num_classes = num_classes\n",
        "\n",
        "#     def forward(self, predictions, targets):\n",
        "#         # Implement loss calculation here\n",
        "#         return loss\n"
      ],
      "metadata": {
        "id": "Ewuf1zjJINfE"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#added own imp\n",
        "def plot_image(image, boxes):\n",
        "    \"\"\"Plots predicted bounding boxes on the image\"\"\"\n",
        "    cmap = plt.get_cmap(\"tab20b\")\n",
        "    class_labels = AllClacess\n",
        "    colors = [cmap(i) for i in np.linspace(0, 1, len(class_labels))]\n",
        "    im = np.array(image)\n",
        "    height, width, _ = im.shape\n",
        "\n",
        "    # Create figure and axes\n",
        "    fig, ax = plt.subplots(1)\n",
        "    # Display the image\n",
        "    ax.imshow(im)\n",
        "\n",
        "    # Create a Rectangle patch\n",
        "    for box in boxes:\n",
        "        assert len(box) == 6, \"box should contain class pred, confidence, x, y, width, height\"\n",
        "        class_pred = box[0]\n",
        "        box = box[2:]\n",
        "        UpperLeft_x = box[0] - box[2] / 2\n",
        "        UpperLeft_y = box[1] - box[3] / 2\n",
        "        rect = patches.Rectangle(\n",
        "            (UpperLeft_x * width, UpperLeft_y * height),\n",
        "            box[2] * width,\n",
        "            box[3] * height,\n",
        "            linewidth=2,\n",
        "            edgecolor=colors[int(class_pred)],\n",
        "            facecolor=\"none\",\n",
        "        )\n",
        "        # Add the patch to the Axes\n",
        "        ax.add_patch(rect)\n",
        "        plt.text(\n",
        "            UpperLeft_x * width,\n",
        "            UpperLeft_y * height,\n",
        "            s=class_labels[int(class_pred)],\n",
        "            color=\"white\",\n",
        "            verticalalignment=\"top\",\n",
        "            bbox={\"color\": colors[int(class_pred)], \"pad\": 0},\n",
        "        )\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "# # Define plotting function\n",
        "#     def plot_image(img, boxes):\n",
        "#     fig, ax = plt.subplots(1, figsize=(12, 9))\n",
        "#     ax.imshow(img)\n",
        "\n",
        "#     for box in boxes:\n",
        "#         x, y, w, h, conf, cls = box\n",
        "#         rect = patches.Rectangle((x, y), w, h, linewidth=1, edgecolor='r', facecolor='none')\n",
        "#         ax.add_patch(rect)\n",
        "#         plt.text(x, y, f'{cls} {conf:.2f}', color='red', fontsize=12)\n",
        "\n",
        "#     plt.show()"
      ],
      "metadata": {
        "id": "k_agKFIIIceJ"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate the model\n",
        "model = YOLOv3(NumClasses=NumClasses).to(DEVICE)\n",
        "\n",
        "# Compile the model\n",
        "optimizer = torch.optim.Adam(\n",
        "    model.parameters(), lr=RateOfLearning\n",
        ")\n",
        "loss_fn = YoloLoss()\n",
        "\n",
        "# Scaler\n",
        "scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "# Train-Test Loader\n",
        "train_loader, test_loader = get_loaders(\n",
        "    train_csv_path='/kaggle/input/pascalvoc-yolo/8examples.csv', test_csv_path='/kaggle/input/pascalvoc-yolo/8examples.csv'\n",
        ")\n",
        "\n",
        "# Anchors\n",
        "scaled_anchors = (\n",
        "    torch.tensor(ANCHORS) * torch.tensor([13,26,52]).unsqueeze(1).unsqueeze(1).repeat(1,3,2)\n",
        ").to(DEVICE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cv1Y_uDpjc9j",
        "outputId": "bcb9d781-31dc-4e29-c0d6-2364e80c8f8b"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wd4w8IsGt17f",
        "outputId": "47c715ee-affd-4e13-9004-83145cc48a70"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  7.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  7.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2, Loss: 0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 11.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3, Loss: 0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 11.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4, Loss: 0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 10.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5, Loss: 0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 11.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6, Loss: 0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 11.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7, Loss: 0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 11.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8, Loss: 0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 10.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9, Loss: 0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 10.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10, Loss: 0.0\n"
          ]
        }
      ],
      "source": [
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    for epoch in range(10):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "\n",
        "        for images, targets in tqdm(train_loader):\n",
        "          if images is None or targets is None:\n",
        "            continue  # Skip the iteration if the image or target is None\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, targets)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        avg_loss = running_loss / len(train_loader)\n",
        "        print(f'Epoch {epoch+1}, Loss: {avg_loss}')\n",
        "\n",
        "        # Log metrics to wandb\n",
        "        wandb.log({\n",
        "            \"epoch\": epoch + 1,\n",
        "            \"loss\": avg_loss\n",
        "        })\n",
        "\n",
        "        # Optionally log model\n",
        "        wandb.watch(model, log=\"all\", log_freq=10)\n",
        "\n",
        "    # Save the model\n",
        "    torch.save(model.state_dict(), \"yolov3_model.pth\")\n",
        "    wandb.save(\"yolov3_model.pth\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs\n",
        "\n",
        "if not os.path.exists('checkpoints'):\n",
        "    os.makedirs('checkpoints')\n",
        "\n",
        "N_EPOCHS = wandb.config.epochs\n",
        "CLIP = 1\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "    start_time = time.time()\n",
        "    end_time = time.time()\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "\n",
        "    wandb.log({\"epoch\": epoch + 1, \"epoch_time_mins\": epoch_mins, \"epoch_time_secs\": epoch_secs})\n",
        "\n",
        "wandb.finish()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287,
          "referenced_widgets": [
            "5ba5f5669f374adfb6c4ccf5d0aee6aa",
            "8ea3c0a4aaed4a5ba5e5cddc59fa6b29",
            "4d1788c78804467da6b4ab33ad3e1594",
            "b91aa325738844beb869a7d43bbeb189",
            "d2b91d352a254abca4571e815f21c84e",
            "f43174e0c7bf4fc8918ac89a2ec339ca",
            "9989405ce86643bdaf5bc6ecd7126951",
            "278de0f70f834d8eb291ab2c75b55c68"
          ]
        },
        "id": "mW6BZRhBua7Q",
        "outputId": "4eb816c2-d348-4dfd-d4b0-a614c98b4680"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5ba5f5669f374adfb6c4ccf5d0aee6aa"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▃▃▃▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇███</td></tr><tr><td>epoch_time_mins</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch_time_secs</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>loss</td><td>▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>30</td></tr><tr><td>epoch_time_mins</td><td>0</td></tr><tr><td>epoch_time_secs</td><td>0</td></tr><tr><td>loss</td><td>0.0</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">vocal-sun-19</strong> at: <a href='https://wandb.ai/mblogge785-work/Untitled10/runs/2vf7sbvu' target=\"_blank\">https://wandb.ai/mblogge785-work/Untitled10/runs/2vf7sbvu</a><br/> View project at: <a href='https://wandb.ai/mblogge785-work/Untitled10' target=\"_blank\">https://wandb.ai/mblogge785-work/Untitled10</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20240805_144235-2vf7sbvu/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
            ]
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "5ba5f5669f374adfb6c4ccf5d0aee6aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8ea3c0a4aaed4a5ba5e5cddc59fa6b29",
              "IPY_MODEL_4d1788c78804467da6b4ab33ad3e1594"
            ],
            "layout": "IPY_MODEL_b91aa325738844beb869a7d43bbeb189"
          }
        },
        "8ea3c0a4aaed4a5ba5e5cddc59fa6b29": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d2b91d352a254abca4571e815f21c84e",
            "placeholder": "​",
            "style": "IPY_MODEL_f43174e0c7bf4fc8918ac89a2ec339ca",
            "value": "235.804 MB of 235.804 MB uploaded\r"
          }
        },
        "4d1788c78804467da6b4ab33ad3e1594": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9989405ce86643bdaf5bc6ecd7126951",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_278de0f70f834d8eb291ab2c75b55c68",
            "value": 1
          }
        },
        "b91aa325738844beb869a7d43bbeb189": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d2b91d352a254abca4571e815f21c84e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f43174e0c7bf4fc8918ac89a2ec339ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9989405ce86643bdaf5bc6ecd7126951": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "278de0f70f834d8eb291ab2c75b55c68": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}