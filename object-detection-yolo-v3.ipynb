{"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["yjwnv6MYoEgc"],"gpuType":"T4","provenance":[]},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":1556326,"sourceType":"datasetVersion","datasetId":918769},{"sourceId":7240078,"sourceType":"datasetVersion","datasetId":4193279}],"dockerImageVersionId":30747,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"papermill":{"default_parameters":{},"duration":12211.677353,"end_time":"2023-12-19T20:51:56.359253","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2023-12-19T17:28:24.681900","version":"2.4.0"}},"nbformat_minor":5,"nbformat":4,"cells":[{"cell_type":"code","source":"# Imports\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as patches\nimport numpy as np\nimport os\n\nimport torch\n\nfrom collections import Counter\nfrom torch.utils.data import DataLoader\nfrom tqdm import tqdm","metadata":{"id":"qwgTtAyp3C7K","papermill":{"duration":4.058162,"end_time":"2023-12-19T17:28:39.273964","exception":false,"start_time":"2023-12-19T17:28:35.215802","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-08-01T06:50:43.061679Z","iopub.execute_input":"2024-08-01T06:50:43.062019Z","iopub.status.idle":"2024-08-01T06:50:43.066955Z","shell.execute_reply.started":"2024-08-01T06:50:43.061990Z","shell.execute_reply":"2024-08-01T06:50:43.066104Z"},"trusted":true},"execution_count":146,"outputs":[]},{"cell_type":"markdown","source":"# YOLO v3 model architecture","metadata":{"id":"yjwnv6MYoEgc","papermill":{"duration":0.011698,"end_time":"2023-12-19T17:28:39.297965","exception":false,"start_time":"2023-12-19T17:28:39.286267","status":"completed"},"tags":[]}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\n\n\"\"\"\nArchitecture config:\n- Tuple --> (filters, kernel_size, stride)\n- List --> ['B', num_repeats] where 'B' is residual block\n- 'S' --> scale prediction block. Also for computing yolo loss\n- 'U' --> upsampling the feature map and concatenating with a previous layer\n\"\"\"\nconfig = [\n    (32, 3, 1),\n    (64, 3, 2),\n    [\"B\", 1],\n    (128, 3, 2),\n    [\"B\", 2],\n    (256, 3, 2),\n    [\"B\", 8],\n    (512, 3, 2),\n    [\"B\", 8],\n    (1024, 3, 2),\n    [\"B\", 4],  # To this point is Darknet-53\n\n    (512, 1, 1),\n    (1024, 3, 1),\n    \"S\",\n    (256, 1, 1),\n    \"U\",\n    (256, 1, 1),\n    (512, 3, 1),\n    \"S\",\n    (128, 1, 1),\n    \"U\",\n    (128, 1, 1),\n    (256, 3, 1),\n    \"S\",\n]\n","metadata":{"id":"zs0uKuG55xC_","papermill":{"duration":0.022597,"end_time":"2023-12-19T17:28:39.332406","exception":false,"start_time":"2023-12-19T17:28:39.309809","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-08-01T06:50:43.068638Z","iopub.execute_input":"2024-08-01T06:50:43.068964Z","iopub.status.idle":"2024-08-01T06:50:43.077388Z","shell.execute_reply.started":"2024-08-01T06:50:43.068941Z","shell.execute_reply":"2024-08-01T06:50:43.076646Z"},"trusted":true},"execution_count":147,"outputs":[]},{"cell_type":"code","source":"class CNNBlock(nn.Module):\n  def __init__(self, in_channels, out_channels, bn_act=True, **kwargs):\n    super(CNNBlock, self).__init__()\n    self.conv = nn.Conv2d(in_channels, out_channels, bias=not bn_act, **kwargs) # If batchnorm layer(bn_act) is true, then bias is False\n    self.bn = nn.BatchNorm2d(out_channels)\n    self.leaky = nn.LeakyReLU(0.1)\n    self.use_bn_act = bn_act\n\n  def forward(self, x):\n    if self.use_bn_act:\n      return self.leaky(self.bn(self.conv(x)))\n    else:\n      return self.conv(x)\n\n\nclass ResidualBlock(nn.Module):\n  def __init__(self, channels, use_residual=True, num_repeats=1):\n    super(ResidualBlock, self).__init__()\n    self.layers = nn.ModuleList() # Like regular python list, but is container for pytorch nn modules\n\n    for repeat in range(num_repeats):\n      self.layers += [\n          nn.Sequential(\n            CNNBlock(channels, channels//2, kernel_size=1),\n            CNNBlock(channels//2, channels, kernel_size=3, padding=1)\n          )\n      ]\n\n    self.use_residual = use_residual\n    self.num_repeats = num_repeats\n\n  def forward(self, x):\n    for layer in self.layers:\n      if self.use_residual:\n        x = x + layer(x)\n      else:\n        x = layer(x)\n\n    return x","metadata":{"id":"Q_zaXn4YQCl7","papermill":{"duration":0.02402,"end_time":"2023-12-19T17:28:39.368315","exception":false,"start_time":"2023-12-19T17:28:39.344295","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-08-01T06:50:43.079257Z","iopub.execute_input":"2024-08-01T06:50:43.079886Z","iopub.status.idle":"2024-08-01T06:50:43.090213Z","shell.execute_reply.started":"2024-08-01T06:50:43.079854Z","shell.execute_reply":"2024-08-01T06:50:43.089492Z"},"trusted":true},"execution_count":148,"outputs":[]},{"cell_type":"code","source":"class ScalePrediction(nn.Module):\n  def __init__(self, in_channels, num_classes):\n    super(ScalePrediction, self).__init__()\n    self.pred = nn.Sequential(\n        CNNBlock(in_channels, 2 * in_channels, kernel_size=3, padding=1),\n        CNNBlock(2 * in_channels, (num_classes + 5) * 3, bn_act=False, kernel_size=1), # (num_classes + 5) * 3 --> (20+5) for each anchor box which in total is 3\n    )\n    self.num_classes = num_classes\n\n  def forward(self, x):\n    return (\n        self.pred(x)\n        .reshape(x.shape[0], 3, self.num_classes + 5, x.shape[2], x.shape[3]) # [batch_size, anchor_boxes, prediction(25), grid_h, grid_w]\n        .permute(0, 1, 3, 4, 2) # [batch_size, anchor_boxes, grid_h, grid_w, prediction(25)]\n      )","metadata":{"id":"IUrOUQNeXDcG","papermill":{"duration":0.021337,"end_time":"2023-12-19T17:28:39.401877","exception":false,"start_time":"2023-12-19T17:28:39.380540","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-08-01T06:50:44.192458Z","iopub.execute_input":"2024-08-01T06:50:44.193101Z","iopub.status.idle":"2024-08-01T06:50:44.200021Z","shell.execute_reply.started":"2024-08-01T06:50:44.193072Z","shell.execute_reply":"2024-08-01T06:50:44.199133Z"},"trusted":true},"execution_count":149,"outputs":[]},{"cell_type":"code","source":"class YOLOv3(nn.Module):\n  def __init__(self, in_channels=3, num_classes=20):\n    super(YOLOv3, self).__init__()\n    self.num_classes = num_classes\n    self.in_channels = in_channels\n    self.layers = self._create_conv_layers()\n\n  def forward(self, x):\n    outputs = []\n    route_connections = []\n\n    for layer in self.layers:\n      if isinstance(layer, ScalePrediction):\n        outputs.append(layer(x))\n        continue\n\n      x = layer(x)\n\n      if isinstance(layer, ResidualBlock) and layer.num_repeats == 8:\n        route_connections.append(x)\n\n      elif isinstance(layer, nn.Upsample):\n        x = torch.cat([x, route_connections[-1]], dim=1)\n        route_connections.pop()\n\n    return outputs\n\n\n  def _create_conv_layers(self):\n    layers = nn.ModuleList()\n    in_channels = self.in_channels\n\n    for module in config:\n      if isinstance(module, tuple):\n        out_channels, kernel_size, stride = module\n        layers.append(CNNBlock(\n            in_channels,\n            out_channels,\n            kernel_size=kernel_size,\n            stride=stride,\n            padding=1 if kernel_size == 3 else 0\n        ))\n        in_channels = out_channels\n\n      elif isinstance(module, list):\n        num_repeats = module[1]\n        layers.append(ResidualBlock(in_channels, num_repeats=num_repeats))\n\n      elif isinstance(module, str):\n        if module == \"S\":\n          layers += [\n              ResidualBlock(in_channels, use_residual=False, num_repeats=1),\n              CNNBlock(in_channels, in_channels//2, kernel_size=1),\n              ScalePrediction(in_channels//2, num_classes = self.num_classes)\n          ]\n          in_channels = in_channels // 2\n\n        elif module == \"U\":\n          layers.append(nn.Upsample(scale_factor=2))\n          in_channels = in_channels * 3\n\n    return layers\n","metadata":{"id":"iwYyoG0AQXtj","papermill":{"duration":0.026458,"end_time":"2023-12-19T17:28:39.440149","exception":false,"start_time":"2023-12-19T17:28:39.413691","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-08-01T06:50:44.211398Z","iopub.execute_input":"2024-08-01T06:50:44.211683Z","iopub.status.idle":"2024-08-01T06:50:44.223547Z","shell.execute_reply.started":"2024-08-01T06:50:44.211659Z","shell.execute_reply":"2024-08-01T06:50:44.222711Z"},"trusted":true},"execution_count":150,"outputs":[]},{"cell_type":"code","source":"num_classes = 20\nIMAGE_SIZE = 416\nmodel = YOLOv3(num_classes=num_classes)\nx = torch.randn((2, 3, IMAGE_SIZE, IMAGE_SIZE))\nout = model(x)\nassert model(x)[0].shape == (2, 3, IMAGE_SIZE//32, IMAGE_SIZE//32, num_classes + 5)\nassert model(x)[1].shape == (2, 3, IMAGE_SIZE//16, IMAGE_SIZE//16, num_classes + 5)\nassert model(x)[2].shape == (2, 3, IMAGE_SIZE//8, IMAGE_SIZE//8, num_classes + 5)\nprint(\"Success!\")","metadata":{"id":"-S2pyv5SmViF","outputId":"a24522a5-0211-475d-8154-518fbcf6d0e5","papermill":{"duration":4.867126,"end_time":"2023-12-19T17:28:44.318961","exception":false,"start_time":"2023-12-19T17:28:39.451835","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-08-01T06:50:44.225265Z","iopub.execute_input":"2024-08-01T06:50:44.225674Z","iopub.status.idle":"2024-08-01T06:50:48.005725Z","shell.execute_reply.started":"2024-08-01T06:50:44.225643Z","shell.execute_reply":"2024-08-01T06:50:48.004659Z"},"trusted":true},"execution_count":151,"outputs":[{"name":"stdout","text":"Success!\n","output_type":"stream"}]},{"cell_type":"code","source":"model(x)[0].shape","metadata":{"id":"jc_-au2vmuSG","outputId":"3a3b154b-6320-4388-f716-3315f7c97f05","papermill":{"duration":0.931755,"end_time":"2023-12-19T17:28:45.263859","exception":false,"start_time":"2023-12-19T17:28:44.332104","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-08-01T06:50:48.007438Z","iopub.execute_input":"2024-08-01T06:50:48.007732Z","iopub.status.idle":"2024-08-01T06:50:48.852113Z","shell.execute_reply.started":"2024-08-01T06:50:48.007707Z","shell.execute_reply":"2024-08-01T06:50:48.851116Z"},"trusted":true},"execution_count":152,"outputs":[{"execution_count":152,"output_type":"execute_result","data":{"text/plain":"torch.Size([2, 3, 13, 13, 25])"},"metadata":{}}]},{"cell_type":"code","source":"model(x)[1].shape","metadata":{"id":"cfXEjuaGn0Ey","outputId":"5ad71d82-0bad-4644-f778-b7b401f3f1ba","papermill":{"duration":0.944934,"end_time":"2023-12-19T17:28:46.221181","exception":false,"start_time":"2023-12-19T17:28:45.276247","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-08-01T06:50:48.853583Z","iopub.execute_input":"2024-08-01T06:50:48.854038Z","iopub.status.idle":"2024-08-01T06:50:49.653770Z","shell.execute_reply.started":"2024-08-01T06:50:48.854004Z","shell.execute_reply":"2024-08-01T06:50:49.652750Z"},"trusted":true},"execution_count":153,"outputs":[{"execution_count":153,"output_type":"execute_result","data":{"text/plain":"torch.Size([2, 3, 26, 26, 25])"},"metadata":{}}]},{"cell_type":"code","source":"model(x)[2].shape","metadata":{"id":"efmVBBZ2n3Ea","outputId":"0134bee6-2d71-4176-cbc8-64b7a92a3b4a","papermill":{"duration":0.92257,"end_time":"2023-12-19T17:28:47.156161","exception":false,"start_time":"2023-12-19T17:28:46.233591","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-08-01T06:50:49.655946Z","iopub.execute_input":"2024-08-01T06:50:49.656266Z","iopub.status.idle":"2024-08-01T06:50:50.477787Z","shell.execute_reply.started":"2024-08-01T06:50:49.656240Z","shell.execute_reply":"2024-08-01T06:50:50.476780Z"},"trusted":true},"execution_count":154,"outputs":[{"execution_count":154,"output_type":"execute_result","data":{"text/plain":"torch.Size([2, 3, 52, 52, 25])"},"metadata":{}}]},{"cell_type":"code","source":"model","metadata":{"papermill":{"duration":0.025337,"end_time":"2023-12-19T17:28:47.195088","exception":false,"start_time":"2023-12-19T17:28:47.169751","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-08-01T06:50:50.478835Z","iopub.execute_input":"2024-08-01T06:50:50.479119Z","iopub.status.idle":"2024-08-01T06:50:50.490247Z","shell.execute_reply.started":"2024-08-01T06:50:50.479095Z","shell.execute_reply":"2024-08-01T06:50:50.489377Z"},"trusted":true},"execution_count":155,"outputs":[{"execution_count":155,"output_type":"execute_result","data":{"text/plain":"YOLOv3(\n  (layers): ModuleList(\n    (0): CNNBlock(\n      (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (leaky): LeakyReLU(negative_slope=0.1)\n    )\n    (1): CNNBlock(\n      (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (leaky): LeakyReLU(negative_slope=0.1)\n    )\n    (2): ResidualBlock(\n      (layers): ModuleList(\n        (0): Sequential(\n          (0): CNNBlock(\n            (conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (leaky): LeakyReLU(negative_slope=0.1)\n          )\n          (1): CNNBlock(\n            (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (leaky): LeakyReLU(negative_slope=0.1)\n          )\n        )\n      )\n    )\n    (3): CNNBlock(\n      (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (leaky): LeakyReLU(negative_slope=0.1)\n    )\n    (4): ResidualBlock(\n      (layers): ModuleList(\n        (0-1): 2 x Sequential(\n          (0): CNNBlock(\n            (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (leaky): LeakyReLU(negative_slope=0.1)\n          )\n          (1): CNNBlock(\n            (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (leaky): LeakyReLU(negative_slope=0.1)\n          )\n        )\n      )\n    )\n    (5): CNNBlock(\n      (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (leaky): LeakyReLU(negative_slope=0.1)\n    )\n    (6): ResidualBlock(\n      (layers): ModuleList(\n        (0-7): 8 x Sequential(\n          (0): CNNBlock(\n            (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (leaky): LeakyReLU(negative_slope=0.1)\n          )\n          (1): CNNBlock(\n            (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (leaky): LeakyReLU(negative_slope=0.1)\n          )\n        )\n      )\n    )\n    (7): CNNBlock(\n      (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (leaky): LeakyReLU(negative_slope=0.1)\n    )\n    (8): ResidualBlock(\n      (layers): ModuleList(\n        (0-7): 8 x Sequential(\n          (0): CNNBlock(\n            (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (leaky): LeakyReLU(negative_slope=0.1)\n          )\n          (1): CNNBlock(\n            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n            (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (leaky): LeakyReLU(negative_slope=0.1)\n          )\n        )\n      )\n    )\n    (9): CNNBlock(\n      (conv): Conv2d(512, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (leaky): LeakyReLU(negative_slope=0.1)\n    )\n    (10): ResidualBlock(\n      (layers): ModuleList(\n        (0-3): 4 x Sequential(\n          (0): CNNBlock(\n            (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (leaky): LeakyReLU(negative_slope=0.1)\n          )\n          (1): CNNBlock(\n            (conv): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n            (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (leaky): LeakyReLU(negative_slope=0.1)\n          )\n        )\n      )\n    )\n    (11): CNNBlock(\n      (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (leaky): LeakyReLU(negative_slope=0.1)\n    )\n    (12): CNNBlock(\n      (conv): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (leaky): LeakyReLU(negative_slope=0.1)\n    )\n    (13): ResidualBlock(\n      (layers): ModuleList(\n        (0): Sequential(\n          (0): CNNBlock(\n            (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (leaky): LeakyReLU(negative_slope=0.1)\n          )\n          (1): CNNBlock(\n            (conv): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n            (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (leaky): LeakyReLU(negative_slope=0.1)\n          )\n        )\n      )\n    )\n    (14): CNNBlock(\n      (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (leaky): LeakyReLU(negative_slope=0.1)\n    )\n    (15): ScalePrediction(\n      (pred): Sequential(\n        (0): CNNBlock(\n          (conv): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (leaky): LeakyReLU(negative_slope=0.1)\n        )\n        (1): CNNBlock(\n          (conv): Conv2d(1024, 75, kernel_size=(1, 1), stride=(1, 1))\n          (bn): BatchNorm2d(75, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (leaky): LeakyReLU(negative_slope=0.1)\n        )\n      )\n    )\n    (16): CNNBlock(\n      (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (leaky): LeakyReLU(negative_slope=0.1)\n    )\n    (17): Upsample(scale_factor=2.0, mode='nearest')\n    (18): CNNBlock(\n      (conv): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (leaky): LeakyReLU(negative_slope=0.1)\n    )\n    (19): CNNBlock(\n      (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (leaky): LeakyReLU(negative_slope=0.1)\n    )\n    (20): ResidualBlock(\n      (layers): ModuleList(\n        (0): Sequential(\n          (0): CNNBlock(\n            (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (leaky): LeakyReLU(negative_slope=0.1)\n          )\n          (1): CNNBlock(\n            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n            (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (leaky): LeakyReLU(negative_slope=0.1)\n          )\n        )\n      )\n    )\n    (21): CNNBlock(\n      (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (leaky): LeakyReLU(negative_slope=0.1)\n    )\n    (22): ScalePrediction(\n      (pred): Sequential(\n        (0): CNNBlock(\n          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (leaky): LeakyReLU(negative_slope=0.1)\n        )\n        (1): CNNBlock(\n          (conv): Conv2d(512, 75, kernel_size=(1, 1), stride=(1, 1))\n          (bn): BatchNorm2d(75, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (leaky): LeakyReLU(negative_slope=0.1)\n        )\n      )\n    )\n    (23): CNNBlock(\n      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (leaky): LeakyReLU(negative_slope=0.1)\n    )\n    (24): Upsample(scale_factor=2.0, mode='nearest')\n    (25): CNNBlock(\n      (conv): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (leaky): LeakyReLU(negative_slope=0.1)\n    )\n    (26): CNNBlock(\n      (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (leaky): LeakyReLU(negative_slope=0.1)\n    )\n    (27): ResidualBlock(\n      (layers): ModuleList(\n        (0): Sequential(\n          (0): CNNBlock(\n            (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (leaky): LeakyReLU(negative_slope=0.1)\n          )\n          (1): CNNBlock(\n            (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (leaky): LeakyReLU(negative_slope=0.1)\n          )\n        )\n      )\n    )\n    (28): CNNBlock(\n      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (leaky): LeakyReLU(negative_slope=0.1)\n    )\n    (29): ScalePrediction(\n      (pred): Sequential(\n        (0): CNNBlock(\n          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (leaky): LeakyReLU(negative_slope=0.1)\n        )\n        (1): CNNBlock(\n          (conv): Conv2d(256, 75, kernel_size=(1, 1), stride=(1, 1))\n          (bn): BatchNorm2d(75, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (leaky): LeakyReLU(negative_slope=0.1)\n        )\n      )\n    )\n  )\n)"},"metadata":{}}]},{"cell_type":"code","source":"# Count the total trainable parameters\ntotal_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\nprint(f\"Total trainable parameters: {total_params}\")","metadata":{"papermill":{"duration":0.022954,"end_time":"2023-12-19T17:28:47.230899","exception":false,"start_time":"2023-12-19T17:28:47.207945","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-08-01T06:50:50.491558Z","iopub.execute_input":"2024-08-01T06:50:50.491861Z","iopub.status.idle":"2024-08-01T06:50:50.499427Z","shell.execute_reply.started":"2024-08-01T06:50:50.491831Z","shell.execute_reply":"2024-08-01T06:50:50.498452Z"},"trusted":true},"execution_count":156,"outputs":[{"name":"stdout","text":"Total trainable parameters: 61626499\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Config File","metadata":{"id":"dj8JoGrytb6y","papermill":{"duration":0.012705,"end_time":"2023-12-19T17:28:47.256538","exception":false,"start_time":"2023-12-19T17:28:47.243833","status":"completed"},"tags":[]}},{"cell_type":"code","source":"import cv2\nimport torch\n\nDEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\nNUM_WORKERS = 4\nBATCH_SIZE = 32\nIMAGE_SIZE = 416\nNUM_CLASSES = 20\nLEARNING_RATE = 1e-5\nNUM_EPOCHS = 80\nCONF_THRESHOLD = 0.8\nMAP_IOU_THRESH = 0.5\nNMS_IOU_THRESH = 0.45\nS = [IMAGE_SIZE // 32, IMAGE_SIZE // 16, IMAGE_SIZE // 8]\n\nIMG_DIR = \"/kaggle/input/pascalvoc-yolo/images\"\nLABEL_DIR = \"/kaggle/input/pascalvoc-yolo/labels\"\n\nANCHORS = [\n    [(0.28, 0.22), (0.38, 0.48), (0.9, 0.78)],\n    [(0.07, 0.15), (0.15, 0.11), (0.14, 0.29)],\n    [(0.02, 0.03), (0.04, 0.07), (0.08, 0.06)],\n] \n\n\nPASCAL_CLASSES = [\n    \"aeroplane\",\n    \"bicycle\",\n    \"bird\",\n    \"boat\",\n    \"bottle\",\n    \"bus\",\n    \"car\",\n    \"cat\",\n    \"chair\",\n    \"cow\",\n    \"diningtable\",\n    \"dog\",\n    \"horse\",\n    \"motorbike\",\n    \"person\",\n    \"pottedplant\",\n    \"sheep\",\n    \"sofa\",\n    \"train\",\n    \"tvmonitor\"\n]","metadata":{"id":"9Ai7PMaUteOY","papermill":{"duration":0.371109,"end_time":"2023-12-19T17:28:47.640461","exception":false,"start_time":"2023-12-19T17:28:47.269352","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-08-01T06:50:50.500675Z","iopub.execute_input":"2024-08-01T06:50:50.501281Z","iopub.status.idle":"2024-08-01T06:50:50.509764Z","shell.execute_reply.started":"2024-08-01T06:50:50.501248Z","shell.execute_reply":"2024-08-01T06:50:50.508763Z"},"trusted":true},"execution_count":157,"outputs":[]},{"cell_type":"markdown","source":"# IOU width height\n- Take in hxw of anchor boxe and bounding box to calc. IOU","metadata":{"id":"aGho3C7Zw5jk","papermill":{"duration":0.013038,"end_time":"2023-12-19T17:28:47.666849","exception":false,"start_time":"2023-12-19T17:28:47.653811","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def iou_width_height(boxes1, boxes2):\n    \"\"\"\n    Parameters:\n        boxes1 (tensor): width and height of the first bounding boxes\n        boxes2 (tensor): width and height of the second bounding boxes\n    Returns:\n        tensor: Intersection over union of the corresponding boxes\n    \"\"\"\n    intersection = torch.min(boxes1[..., 0], boxes2[..., 0]) * torch.min(\n        boxes1[..., 1], boxes2[..., 1]\n    )\n    union = (\n        boxes1[..., 0] * boxes1[..., 1] + boxes2[..., 0] * boxes2[..., 1] - intersection\n    )\n    return intersection / union","metadata":{"id":"4P448jivxbnu","papermill":{"duration":0.021393,"end_time":"2023-12-19T17:28:47.701182","exception":false,"start_time":"2023-12-19T17:28:47.679789","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-08-01T06:50:50.510932Z","iopub.execute_input":"2024-08-01T06:50:50.511375Z","iopub.status.idle":"2024-08-01T06:50:50.518036Z","shell.execute_reply.started":"2024-08-01T06:50:50.511343Z","shell.execute_reply":"2024-08-01T06:50:50.517139Z"},"trusted":true},"execution_count":158,"outputs":[]},{"cell_type":"markdown","source":"# Intersection over union","metadata":{"id":"uXiVIrYjxfnO","papermill":{"duration":0.012568,"end_time":"2023-12-19T17:28:47.726268","exception":false,"start_time":"2023-12-19T17:28:47.713700","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def intersection_over_union(boxes_preds, boxes_labels, box_format=\"midpoint\"):\n    \"\"\"\n    This function calculates intersection over union (iou) given pred boxes\n    and target boxes.\n\n    Parameters:\n        boxes_preds (tensor): Predictions of Bounding Boxes (BATCH_SIZE, 4)\n        boxes_labels (tensor): Correct labels of Bounding Boxes (BATCH_SIZE, 4)\n        box_format (str): midpoint/corners, if boxes (x,y,w,h) or (x1,y1,x2,y2)\n\n    Returns:\n        tensor: Intersection over union for all examples\n    \"\"\"\n\n    if box_format == \"midpoint\":\n        box1_x1 = boxes_preds[..., 0:1] - boxes_preds[..., 2:3] / 2\n        box1_y1 = boxes_preds[..., 1:2] - boxes_preds[..., 3:4] / 2\n        box1_x2 = boxes_preds[..., 0:1] + boxes_preds[..., 2:3] / 2\n        box1_y2 = boxes_preds[..., 1:2] + boxes_preds[..., 3:4] / 2\n        box2_x1 = boxes_labels[..., 0:1] - boxes_labels[..., 2:3] / 2\n        box2_y1 = boxes_labels[..., 1:2] - boxes_labels[..., 3:4] / 2\n        box2_x2 = boxes_labels[..., 0:1] + boxes_labels[..., 2:3] / 2\n        box2_y2 = boxes_labels[..., 1:2] + boxes_labels[..., 3:4] / 2\n\n    if box_format == \"corners\":\n        box1_x1 = boxes_preds[..., 0:1]\n        box1_y1 = boxes_preds[..., 1:2]\n        box1_x2 = boxes_preds[..., 2:3]\n        box1_y2 = boxes_preds[..., 3:4]\n        box2_x1 = boxes_labels[..., 0:1]\n        box2_y1 = boxes_labels[..., 1:2]\n        box2_x2 = boxes_labels[..., 2:3]\n        box2_y2 = boxes_labels[..., 3:4]\n\n    x1 = torch.max(box1_x1, box2_x1)\n    y1 = torch.max(box1_y1, box2_y1)\n    x2 = torch.min(box1_x2, box2_x2)\n    y2 = torch.min(box1_y2, box2_y2)\n\n    intersection = (x2 - x1).clamp(0) * (y2 - y1).clamp(0)\n    box1_area = abs((box1_x2 - box1_x1) * (box1_y2 - box1_y1))\n    box2_area = abs((box2_x2 - box2_x1) * (box2_y2 - box2_y1))\n\n    return intersection / (box1_area + box2_area - intersection + 1e-6)","metadata":{"id":"RvwUplkYxqrw","papermill":{"duration":0.027159,"end_time":"2023-12-19T17:28:47.766138","exception":false,"start_time":"2023-12-19T17:28:47.738979","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-08-01T06:50:50.519255Z","iopub.execute_input":"2024-08-01T06:50:50.519932Z","iopub.status.idle":"2024-08-01T06:50:50.532250Z","shell.execute_reply.started":"2024-08-01T06:50:50.519899Z","shell.execute_reply":"2024-08-01T06:50:50.531501Z"},"trusted":true},"execution_count":159,"outputs":[]},{"cell_type":"markdown","source":"# Non-max Supression","metadata":{"id":"IkcXigCkxv9_","papermill":{"duration":0.012963,"end_time":"2023-12-19T17:28:47.791943","exception":false,"start_time":"2023-12-19T17:28:47.778980","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def non_max_suppression(bboxes, iou_threshold, threshold, box_format=\"corners\"):\n    \"\"\"\n     Does Non Max Suppression given bboxes\n\n    Parameters:\n        bboxes (list): list of lists containing all bboxes with each bboxes\n        specified as [class_pred, prob_score, x1, y1, x2, y2]\n        iou_threshold (float): threshold where predicted bboxes is correct\n        threshold (float): threshold to remove predicted bboxes (independent of IoU)\n        box_format (str): \"midpoint\" or \"corners\" used to specify bboxes\n\n    Returns:\n        list: bboxes after performing NMS given a specific IoU threshold\n    \"\"\"\n\n    assert type(bboxes) == list\n\n    bboxes = [box for box in bboxes if box[1] > threshold]\n    bboxes = sorted(bboxes, key=lambda x: x[1], reverse=True)\n    bboxes_after_nms = []\n\n    while bboxes:\n        chosen_box = bboxes.pop(0)\n\n        bboxes = [\n            box\n            for box in bboxes\n            if box[0] != chosen_box[0]\n            or intersection_over_union(\n                torch.tensor(chosen_box[2:]),\n                torch.tensor(box[2:]),\n                box_format=box_format,\n            )\n            < iou_threshold\n        ]\n\n        bboxes_after_nms.append(chosen_box)\n\n    return bboxes_after_nms","metadata":{"id":"0oIq_NZpxzNi","papermill":{"duration":0.022558,"end_time":"2023-12-19T17:28:47.827509","exception":false,"start_time":"2023-12-19T17:28:47.804951","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-08-01T06:50:50.535979Z","iopub.execute_input":"2024-08-01T06:50:50.536291Z","iopub.status.idle":"2024-08-01T06:50:50.543793Z","shell.execute_reply.started":"2024-08-01T06:50:50.536268Z","shell.execute_reply":"2024-08-01T06:50:50.542982Z"},"trusted":true},"execution_count":160,"outputs":[]},{"cell_type":"markdown","source":"# Dataset","metadata":{"id":"6qWub9xCoJQP","papermill":{"duration":0.012761,"end_time":"2023-12-19T17:28:47.853131","exception":false,"start_time":"2023-12-19T17:28:47.840370","status":"completed"},"tags":[]}},{"cell_type":"code","source":"import numpy as np\nimport os\nimport pandas as pd\nimport torch\n\nfrom torch.utils.data import Dataset, DataLoader\nfrom PIL import Image, ImageFile","metadata":{"id":"17VUsG5An6ED","papermill":{"duration":0.019761,"end_time":"2023-12-19T17:28:47.885721","exception":false,"start_time":"2023-12-19T17:28:47.865960","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-08-01T06:50:50.544801Z","iopub.execute_input":"2024-08-01T06:50:50.545094Z","iopub.status.idle":"2024-08-01T06:50:50.553991Z","shell.execute_reply.started":"2024-08-01T06:50:50.545059Z","shell.execute_reply":"2024-08-01T06:50:50.553218Z"},"trusted":true},"execution_count":161,"outputs":[]},{"cell_type":"code","source":"# allows PIL to load images even if they are truncated or incomplete\nImageFile.LOAD_TRUNCATED_IMAGES = True","metadata":{"id":"Lfov94HNpy4C","papermill":{"duration":0.018826,"end_time":"2023-12-19T17:28:47.917203","exception":false,"start_time":"2023-12-19T17:28:47.898377","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-08-01T06:50:50.555280Z","iopub.execute_input":"2024-08-01T06:50:50.555614Z","iopub.status.idle":"2024-08-01T06:50:50.561511Z","shell.execute_reply.started":"2024-08-01T06:50:50.555583Z","shell.execute_reply":"2024-08-01T06:50:50.560731Z"},"trusted":true},"execution_count":162,"outputs":[]},{"cell_type":"code","source":"class YOLODataset(Dataset):\n  def __init__(self, csv_file, img_dir, label_dir, anchors,\n               image_size=416, S=[13,26,52], C=20, transform=None):\n    self.annotations = pd.read_csv(csv_file)\n    self.img_dir = img_dir\n    self.label_dir = label_dir\n    self.transform = transform\n    self.S = S\n\n    # Suppose, anchors[0] = [a,b,c], anchors[1] = [d,e,f], anchors[2] = [g,h,i] : Each set of anchors for each scale\n    # List addition gives shape 3x3\n    # Anchors per scale suggests that there are three different aspect ratios for each anchor position.\n    self.anchors = torch.tensor(anchors[0] + anchors[1] + anchors[2]) # For all 3 scales\n    self.num_anchors = self.anchors.shape[0]\n    self.num_anchors_per_scale = self.num_anchors // 3\n\n    self.C = C\n\n    # If a cell has obj. then one anchor is responsible for outputting it,\n    # one that's responsible is the one that has highest iou with ground truth box\n    # but, there might be cases where there are several boxes in the same cell\n    self.ignore_iou_thresh = 0.5\n\n  def __len__(self):\n    return len(self.annotations)\n\n  def __getitem__(self, index):\n    label_path = os.path.join(self.label_dir, self.annotations.iloc[index, 1])\n    bboxes = np.roll(np.loadtxt(fname=label_path, delimiter=\" \", ndmin=2), 4, axis=1).tolist() # np.roll with shift 4 on axis 1: [class, x, y, w, h] --> [x, y, w, h, class]\n\n    img_path = os.path.join(self.img_dir, self.annotations.iloc[index, 0])\n    image = Image.open(img_path)\n\n    if self.transform:\n      image = self.transform(image)\n\n    targets = [torch.zeros((self.num_anchors // 3, S, S, 6)) for S in self.S] # 6 because objectness score, bounding box coordinates (x, y, w, h), class label\n\n    for box in bboxes:\n      \"\"\"For each box in bboxes,\n      we want to assign which anchor should be responsible and\n      which cell should be responsible for all the three different scales prediction\"\"\"\n      iou_anchors = iou_width_height(torch.tensor(box[2:4]), self.anchors) # IOU from height and width\n      anchor_indices = iou_anchors.argsort(descending=True, dim=0) # Sorting sucht that the first is the best anchor\n\n      x, y, width, height, class_label = box\n      has_anchor = [False, False, False] # Make sure there is an anchor for each of three scales for each bounding box\n\n      for anchor_idx in anchor_indices:\n        scale_idx = anchor_idx // self.num_anchors_per_scale # scale_idx is either 0,1,2: 0-->13x13, 1:-->26x26, 2:-->52x52\n        anchor_on_scale = anchor_idx % self.num_anchors_per_scale # In each scale, choosing the anchor thats either 0,1,2\n\n        S = self.S[scale_idx]\n        i, j = int(S*y), int(S*x) # x=0.5, S=13 --> int(6.5) = 6 | i=y cell, j=x cell\n        anchor_taken = targets[scale_idx][anchor_on_scale, i, j, 0]\n\n        if not anchor_taken and not has_anchor[scale_idx]:\n          targets[scale_idx][anchor_on_scale, i, j, 0] = 1\n          x_cell, y_cell = S*x - j, S*y - i # 6.5 - 6 = 0.5 such that they are between [0,1]\n          width_cell, height_cell = (\n              width*S, # S=13, width=0.5, 6.5\n              height*S\n          )\n\n          box_coordinates = torch.tensor([x_cell, y_cell, width_cell, height_cell])\n\n          targets[scale_idx][anchor_on_scale, i, j, 1:5] = box_coordinates\n          targets[scale_idx][anchor_on_scale, i, j, 5] = int(class_label)\n          has_anchor[scale_idx] = True\n\n        # Even if the same grid shares another anchor having iou>ignore_iou_thresh then,\n        elif not anchor_taken and iou_anchors[anchor_idx] > self.ignore_iou_thresh:\n          targets[scale_idx][anchor_on_scale, i, j, 0] = -1 # ignore this prediction\n\n    return image, tuple(targets)\n","metadata":{"id":"UiM8IiJeqIV4","papermill":{"duration":0.031674,"end_time":"2023-12-19T17:28:47.961698","exception":false,"start_time":"2023-12-19T17:28:47.930024","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-08-01T06:50:50.562793Z","iopub.execute_input":"2024-08-01T06:50:50.563085Z","iopub.status.idle":"2024-08-01T06:50:50.580041Z","shell.execute_reply.started":"2024-08-01T06:50:50.563061Z","shell.execute_reply":"2024-08-01T06:50:50.579082Z"},"trusted":true},"execution_count":163,"outputs":[]},{"cell_type":"markdown","source":"# DataLoader","metadata":{"id":"lJRincdJzCyU","papermill":{"duration":0.012839,"end_time":"2023-12-19T17:28:47.987602","exception":false,"start_time":"2023-12-19T17:28:47.974763","status":"completed"},"tags":[]}},{"cell_type":"code","source":"import torchvision.transforms as transforms\ntransform = transforms.Compose([transforms.Resize((416, 416)), transforms.ToTensor()])","metadata":{"id":"BsljMXYuXndg","papermill":{"duration":0.325693,"end_time":"2023-12-19T17:28:48.326146","exception":false,"start_time":"2023-12-19T17:28:48.000453","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-08-01T06:50:50.581288Z","iopub.execute_input":"2024-08-01T06:50:50.581631Z","iopub.status.idle":"2024-08-01T06:50:50.590373Z","shell.execute_reply.started":"2024-08-01T06:50:50.581599Z","shell.execute_reply":"2024-08-01T06:50:50.589476Z"},"trusted":true},"execution_count":164,"outputs":[]},{"cell_type":"code","source":"def get_loaders(train_csv_path, test_csv_path):\n\n    train_dataset = YOLODataset(\n        train_csv_path,\n        transform=transform,\n        S=[IMAGE_SIZE // 32, IMAGE_SIZE // 16, IMAGE_SIZE // 8],\n        img_dir=IMG_DIR,\n        label_dir=LABEL_DIR,\n        anchors=ANCHORS,\n    )\n    test_dataset = YOLODataset(\n        test_csv_path,\n        transform=transform,\n        S=[IMAGE_SIZE // 32, IMAGE_SIZE // 16, IMAGE_SIZE // 8],\n        img_dir=IMG_DIR,\n        label_dir=LABEL_DIR,\n        anchors=ANCHORS,\n    )\n    train_loader = DataLoader(\n        dataset=train_dataset,\n        batch_size=BATCH_SIZE,\n        shuffle=True,\n        drop_last=False,\n    )\n    test_loader = DataLoader(\n        dataset=test_dataset,\n        batch_size=BATCH_SIZE,\n        shuffle=False,\n        drop_last=False,\n    )\n\n    return train_loader, test_loader","metadata":{"id":"10SzzqKdzExo","papermill":{"duration":0.028829,"end_time":"2023-12-19T17:28:48.374519","exception":false,"start_time":"2023-12-19T17:28:48.345690","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-08-01T06:52:11.349125Z","iopub.execute_input":"2024-08-01T06:52:11.349959Z","iopub.status.idle":"2024-08-01T06:52:11.356666Z","shell.execute_reply.started":"2024-08-01T06:52:11.349928Z","shell.execute_reply":"2024-08-01T06:52:11.355750Z"},"trusted":true},"execution_count":175,"outputs":[]},{"cell_type":"markdown","source":"# Mean Average Precision","metadata":{"papermill":{"duration":0.012854,"end_time":"2023-12-19T17:28:48.403652","exception":false,"start_time":"2023-12-19T17:28:48.390798","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def mean_average_precision(\n    pred_boxes, true_boxes, iou_threshold=0.5, box_format=\"midpoint\", num_classes=4\n):\n    \"\"\"\n    Video explanation of this function:\n    https://youtu.be/FppOzcDvaDI\n\n    This function calculates mean average precision (mAP)\n\n    Parameters:\n        pred_boxes (list): list of lists containing all bboxes with each bboxes\n        specified as [train_idx, class_prediction, prob_score, x1, y1, x2, y2]\n        true_boxes (list): Similar as pred_boxes except all the correct ones\n        iou_threshold (float): threshold where predicted bboxes is correct\n        box_format (str): \"midpoint\" or \"corners\" used to specify bboxes\n        num_classes (int): number of classes\n\n    Returns:\n        float: mAP value across all classes given a specific IoU threshold\n    \"\"\"\n\n    # list storing all AP for respective classes\n    average_precisions = []\n\n    # used for numerical stability later on\n    epsilon = 1e-6\n\n    for c in range(num_classes):\n        detections = []\n        ground_truths = []\n\n        # Go through all predictions and targets,\n        # and only add the ones that belong to the\n        # current class c\n        for detection in pred_boxes:\n            if detection[1] == c:\n                detections.append(detection)\n\n        for true_box in true_boxes:\n            if true_box[1] == c:\n                ground_truths.append(true_box)\n\n        # find the amount of bboxes for each training example\n        # Counter here finds how many ground truth bboxes we get\n        # for each training example, so let's say img 0 has 3,\n        # img 1 has 5 then we will obtain a dictionary with:\n        # amount_bboxes = {0:3, 1:5}\n        amount_bboxes = Counter([gt[0] for gt in ground_truths])\n\n        # We then go through each key, val in this dictionary\n        # and convert to the following (w.r.t same example):\n        # ammount_bboxes = {0:torch.tensor[0,0,0], 1:torch.tensor[0,0,0,0,0]}\n        for key, val in amount_bboxes.items():\n            amount_bboxes[key] = torch.zeros(val)\n\n        # sort by box probabilities which is index 2\n        detections.sort(key=lambda x: x[2], reverse=True)\n        TP = torch.zeros((len(detections)))\n        FP = torch.zeros((len(detections)))\n        total_true_bboxes = len(ground_truths)\n\n        # If none exists for this class then we can safely skip\n        if total_true_bboxes == 0:\n            continue\n\n        for detection_idx, detection in enumerate(detections):\n            # Only take out the ground_truths that have the same\n            # training idx as detection\n            ground_truth_img = [\n                bbox for bbox in ground_truths if bbox[0] == detection[0]\n            ]\n\n            num_gts = len(ground_truth_img)\n            best_iou = 0\n\n            for idx, gt in enumerate(ground_truth_img):\n                iou = intersection_over_union(\n                    torch.tensor(detection[3:]),\n                    torch.tensor(gt[3:]),\n                    box_format=box_format,\n                )\n\n                if iou > best_iou:\n                    best_iou = iou\n                    best_gt_idx = idx\n\n            if best_iou > iou_threshold:\n                # only detect ground truth detection once\n                if amount_bboxes[detection[0]][best_gt_idx] == 0:\n                    # true positive and add this bounding box to seen\n                    TP[detection_idx] = 1\n                    amount_bboxes[detection[0]][best_gt_idx] = 1\n                else:\n                    FP[detection_idx] = 1\n\n            # if IOU is lower then the detection is a false positive\n            else:\n                FP[detection_idx] = 1\n\n        TP_cumsum = torch.cumsum(TP, dim=0)\n        FP_cumsum = torch.cumsum(FP, dim=0)\n        recalls = TP_cumsum / (total_true_bboxes + epsilon)\n        precisions = TP_cumsum / (TP_cumsum + FP_cumsum + epsilon)\n        precisions = torch.cat((torch.tensor([1]), precisions))\n        recalls = torch.cat((torch.tensor([0]), recalls))\n        # torch.trapz for numerical integration\n        average_precisions.append(torch.trapz(precisions, recalls))\n\n    return sum(average_precisions) / len(average_precisions)","metadata":{"papermill":{"duration":0.032317,"end_time":"2023-12-19T17:28:48.448856","exception":false,"start_time":"2023-12-19T17:28:48.416539","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-08-01T06:50:50.601041Z","iopub.execute_input":"2024-08-01T06:50:50.601493Z","iopub.status.idle":"2024-08-01T06:50:50.617826Z","shell.execute_reply.started":"2024-08-01T06:50:50.601463Z","shell.execute_reply":"2024-08-01T06:50:50.616980Z"},"trusted":true},"execution_count":166,"outputs":[]},{"cell_type":"markdown","source":"# Get bboxes and convert cells to bboxes","metadata":{"papermill":{"duration":0.013653,"end_time":"2023-12-19T17:28:48.481809","exception":false,"start_time":"2023-12-19T17:28:48.468156","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def get_evaluation_bboxes(\n    loader,\n    model,\n    iou_threshold,\n    anchors,\n    threshold,\n    box_format=\"midpoint\",\n    device=\"cuda\" if torch.cuda.is_available() else \"cpu\",\n):\n    # make sure model is in eval before get bboxes\n    model.eval()\n    train_idx = 0\n    all_pred_boxes = []\n    all_true_boxes = []\n    for batch_idx, (x, labels) in enumerate(loader):\n        x = x.float().to(device)\n\n        with torch.no_grad():\n            predictions = model(x)\n\n        batch_size = x.shape[0]\n        bboxes = [[] for _ in range(batch_size)]\n        for i in range(3):\n            S = predictions[i].shape[2] # grid cell size for each predictions\n            anchor = torch.tensor([*anchors[i]]).to(device) * S # anchor for each grid, prediction type\n            boxes_scale_i = cells_to_bboxes( # get bboxes for each image in the batch\n                predictions[i], anchor, S=S, is_preds=True\n            )\n            for idx, (box) in enumerate(boxes_scale_i): # for each image, append the bbox to corr. bboxes[idx]\n                bboxes[idx] += box\n\n        # we just want one bbox for each label, not one for each scale\n        true_bboxes = cells_to_bboxes(\n            labels[2], anchor, S=S, is_preds=False\n        )\n\n        for idx in range(batch_size):\n            nms_boxes = non_max_suppression(\n                bboxes[idx],\n                iou_threshold=iou_threshold,\n                threshold=threshold,\n                box_format=box_format,\n            )\n\n            for nms_box in nms_boxes:\n                all_pred_boxes.append([train_idx] + nms_box)\n\n            for box in true_bboxes[idx]:\n                if box[1] > threshold:\n                    all_true_boxes.append([train_idx] + box)\n\n            train_idx += 1\n\n    model.train()\n    return all_pred_boxes, all_true_boxes","metadata":{"papermill":{"duration":0.034433,"end_time":"2023-12-19T17:28:48.529102","exception":false,"start_time":"2023-12-19T17:28:48.494669","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-08-01T06:50:50.618972Z","iopub.execute_input":"2024-08-01T06:50:50.619379Z","iopub.status.idle":"2024-08-01T06:50:50.630479Z","shell.execute_reply.started":"2024-08-01T06:50:50.619348Z","shell.execute_reply":"2024-08-01T06:50:50.629526Z"},"trusted":true},"execution_count":167,"outputs":[]},{"cell_type":"code","source":"def cells_to_bboxes(predictions, anchors, S, is_preds=True):\n    \"\"\"\n    Scales the predictions coming from the model to\n    be relative to the entire image such that they for example later\n    can be plotted or.\n    INPUT:\n    predictions: tensor of size (N, 3, S, S, num_classes+5)\n    anchors: the anchors used for the predictions\n    S: the number of cells the image is divided in on the width (and height)\n    is_preds: whether the input is predictions or the true bounding boxes\n    OUTPUT:\n    converted_bboxes: the converted boxes of sizes (N, num_anchors, S, S, 1+5) with class index,\n                      object score, bounding box coordinates\n    \"\"\"\n    BATCH_SIZE = predictions.shape[0]\n    num_anchors = len(anchors)\n    box_predictions = predictions[..., 1:5]\n    if is_preds:\n        anchors = anchors.reshape(1, len(anchors), 1, 1, 2)\n        box_predictions[..., 0:2] = torch.sigmoid(box_predictions[..., 0:2])\n        box_predictions[..., 2:] = torch.exp(box_predictions[..., 2:]) * anchors\n        scores = torch.sigmoid(predictions[..., 0:1])\n        best_class = torch.argmax(predictions[..., 5:], dim=-1).unsqueeze(-1)\n    else:\n        scores = predictions[..., 0:1]\n        best_class = predictions[..., 5:6]\n\n    cell_indices = (\n        torch.arange(S)\n        .repeat(predictions.shape[0], 3, S, 1)\n        .unsqueeze(-1)\n        .to(predictions.device)\n    )\n    x = 1 / S * (box_predictions[..., 0:1] + cell_indices)\n    y = 1 / S * (box_predictions[..., 1:2] + cell_indices.permute(0, 1, 3, 2, 4))\n    w_h = 1 / S * box_predictions[..., 2:4]\n    converted_bboxes = torch.cat((best_class, scores, x, y, w_h), dim=-1).reshape(BATCH_SIZE, num_anchors * S * S, 6)\n    return converted_bboxes.tolist()","metadata":{"papermill":{"duration":0.029879,"end_time":"2023-12-19T17:28:48.576674","exception":false,"start_time":"2023-12-19T17:28:48.546795","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-08-01T06:50:50.631761Z","iopub.execute_input":"2024-08-01T06:50:50.632016Z","iopub.status.idle":"2024-08-01T06:50:50.642073Z","shell.execute_reply.started":"2024-08-01T06:50:50.631994Z","shell.execute_reply":"2024-08-01T06:50:50.641289Z"},"trusted":true},"execution_count":168,"outputs":[]},{"cell_type":"markdown","source":"# Loss","metadata":{"id":"BlYBUIFvh9yd","papermill":{"duration":0.012777,"end_time":"2023-12-19T17:28:48.602300","exception":false,"start_time":"2023-12-19T17:28:48.589523","status":"completed"},"tags":[]}},{"cell_type":"code","source":"class YoloLoss(nn.Module):\n  def __init__(self):\n    super(YoloLoss, self).__init__()\n    self.mse = nn.MSELoss() # For bounding box loss\n    self.bce = nn.BCEWithLogitsLoss() # For multi-label prediction: Binary cross entropy\n    self.entropy = nn.CrossEntropyLoss() # For classification\n    self.sigmoid = nn.Sigmoid()\n\n    # Constants for significance of obj, or no obj.\n    self.lambda_class = 1\n    self.lambda_noobj = 10\n    self.lambda_obj = 1\n    self.lambda_box = 10\n\n  def forward(self, predictions, target, anchors):\n    obj = target[..., 0] == 1\n    noobj = target[..., 0] == 0\n\n    # No object Loss\n    ################\n    no_object_loss = self.bce(\n        (predictions[..., 0:1][noobj]), (target[..., 0:1][noobj])\n    )\n\n    # Object Loss\n    #############\n    anchors = anchors.reshape(1,3,1,1,2) # Anchors initial shape 3x2 --> 3 anchor boxes each of certain hxw (2)\n\n    # box_preds = [..., sigmoid(x), sigmoid(y), [p_w * exp(t_w)], [p_h * exp(t_h)], ...]\n    box_preds = torch.cat([self.sigmoid(predictions[..., 1:3]), torch.exp(predictions[..., 3:5]) * anchors], dim=-1)\n\n    # iou between predicted box and target box\n    ious = intersection_over_union(box_preds[obj], target[..., 1:5][obj]).detach()\n\n    object_loss = self.bce(\n        (predictions[..., 0:1][obj]), (ious * target[..., 0:1][obj]) # target * iou because only intersected part object loss calc\n    )\n\n    # Box Coordinate Loss\n    #####################\n    predictions[..., 1:3] = self.sigmoid(predictions[..., 1:3]) # x, y to be between [0,1]\n    target[..., 3:5] = torch.log(\n        (1e-6 + target[..., 3:5] / anchors)\n    ) # Exponential of hxw (taking log because opp. of exp)\n\n    box_loss = self.mse(predictions[..., 1:5][obj], target[..., 1:5][obj])\n\n    # Class Loss\n    ############\n    class_loss = self.entropy(\n        (predictions[..., 5:][obj]), (target[..., 5][obj].long())\n    )\n\n    return(\n        self.lambda_box * box_loss\n        + self.lambda_obj * object_loss\n        + self.lambda_noobj * no_object_loss\n        + self.lambda_class * class_loss\n    )\n","metadata":{"id":"i5nJTWLRiAY1","papermill":{"duration":0.032184,"end_time":"2023-12-19T17:28:48.648025","exception":false,"start_time":"2023-12-19T17:28:48.615841","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-08-01T06:50:50.643100Z","iopub.execute_input":"2024-08-01T06:50:50.643397Z","iopub.status.idle":"2024-08-01T06:50:50.656749Z","shell.execute_reply.started":"2024-08-01T06:50:50.643375Z","shell.execute_reply":"2024-08-01T06:50:50.655998Z"},"trusted":true},"execution_count":169,"outputs":[]},{"cell_type":"markdown","source":"# Plot Image","metadata":{"id":"M2mlDBxU2pjJ","papermill":{"duration":0.012422,"end_time":"2023-12-19T17:28:48.673454","exception":false,"start_time":"2023-12-19T17:28:48.661032","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def plot_image(image, boxes):\n    \"\"\"Plots predicted bounding boxes on the image\"\"\"\n    cmap = plt.get_cmap(\"tab20b\")\n    class_labels = PASCAL_CLASSES\n    colors = [cmap(i) for i in np.linspace(0, 1, len(class_labels))]\n    im = np.array(image)\n    height, width, _ = im.shape\n\n    # Create figure and axes\n    fig, ax = plt.subplots(1)\n    # Display the image\n    ax.imshow(im)\n\n    # box[0] is x midpoint, box[2] is width\n    # box[1] is y midpoint, box[3] is height\n\n    # Create a Rectangle patch\n    for box in boxes:\n        assert len(box) == 6, \"box should contain class pred, confidence, x, y, width, height\"\n        class_pred = box[0]\n        box = box[2:]\n        upper_left_x = box[0] - box[2] / 2\n        upper_left_y = box[1] - box[3] / 2\n        rect = patches.Rectangle(\n            (upper_left_x * width, upper_left_y * height),\n            box[2] * width,\n            box[3] * height,\n            linewidth=2,\n            edgecolor=colors[int(class_pred)],\n            facecolor=\"none\",\n        )\n        # Add the patch to the Axes\n        ax.add_patch(rect)\n        plt.text(\n            upper_left_x * width,\n            upper_left_y * height,\n            s=class_labels[int(class_pred)],\n            color=\"white\",\n            verticalalignment=\"top\",\n            bbox={\"color\": colors[int(class_pred)], \"pad\": 0},\n        )\n\n    plt.show()","metadata":{"id":"Xjl_AldR2rX9","papermill":{"duration":0.02615,"end_time":"2023-12-19T17:28:48.712437","exception":false,"start_time":"2023-12-19T17:28:48.686287","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-08-01T06:50:50.657652Z","iopub.execute_input":"2024-08-01T06:50:50.658561Z","iopub.status.idle":"2024-08-01T06:50:50.667919Z","shell.execute_reply.started":"2024-08-01T06:50:50.658534Z","shell.execute_reply":"2024-08-01T06:50:50.667112Z"},"trusted":true},"execution_count":170,"outputs":[]},{"cell_type":"markdown","source":"# Training","metadata":{"id":"--AS2dslvM-D","papermill":{"duration":0.012926,"end_time":"2023-12-19T17:28:48.743475","exception":false,"start_time":"2023-12-19T17:28:48.730549","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Save test loader to a file\ntorch.save(test_loader, '/kaggle/working/test_loader.pth')","metadata":{"papermill":{"duration":0.032205,"end_time":"2023-12-19T17:28:52.401408","exception":false,"start_time":"2023-12-19T17:28:52.369203","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-08-01T06:52:35.518819Z","iopub.execute_input":"2024-08-01T06:52:35.519685Z","iopub.status.idle":"2024-08-01T06:52:35.549077Z","shell.execute_reply.started":"2024-08-01T06:52:35.519652Z","shell.execute_reply":"2024-08-01T06:52:35.547855Z"},"trusted":true},"execution_count":177,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[177], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Save test loader to a file\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m torch\u001b[38;5;241m.\u001b[39msave(\u001b[43mtest_loader\u001b[49m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/kaggle/working/test_loader.pth\u001b[39m\u001b[38;5;124m'\u001b[39m)\n","\u001b[0;31mNameError\u001b[0m: name 'test_loader' is not defined"],"ename":"NameError","evalue":"name 'test_loader' is not defined","output_type":"error"}]},{"cell_type":"code","source":"import torch.optim as optim\n\nfrom tqdm import tqdm\nimport time\n\nhistory_loss = [] # To plot the epoch vs. loss\n\nfor epoch in tqdm(range(NUM_EPOCHS), desc=\"Epochs\"):\n  model.train()\n\n  losses = []\n\n  start_time = time.time() # Start time of the epoch\n\n  for batch_idx, (x,y) in enumerate(train_loader):\n    x = x.to(DEVICE)\n    y0, y1, y2 = (y[0].to(DEVICE),\n                  y[1].to(DEVICE),\n                  y[2].to(DEVICE))\n\n    # context manager is used in PyTorch to automatically handle mixed-precision computations on CUDA-enabled GPUs\n    with torch.cuda.amp.autocast():\n      out = model(x)\n      loss = (\n          loss_fn(out[0], y0, scaled_anchors[0])\n          + loss_fn(out[1], y1, scaled_anchors[1])\n          + loss_fn(out[2], y2, scaled_anchors[2])\n      )\n\n    losses.append(loss.item())\n    \n    optimizer.zero_grad()\n    scaler.scale(loss).backward()\n    scaler.step(optimizer)\n    scaler.update()\n\n  end_time = time.time()  # End time of the epoch\n  epoch_duration = end_time - start_time  # Duration of the epoch\n    \n  history_loss.append(sum(losses)/len(losses))\n\n  if (epoch+1) % 10 == 0:\n    # Print the epoch duration\n    tqdm.write(f\"Epoch {epoch+1} completed in {epoch_duration:.2f} seconds\")\n\n    # Print the loss and accuracy for training and validation data\n    print(f\"Epoch [{epoch+1}/{NUM_EPOCHS}], \"\n          f\"Loss: {sum(losses)/len(losses):.4f}\")\n\n    # save the model after every 10 epoch\n    torch.save(model.state_dict(), f'/kaggle/working/Yolov3_epoch{epoch+1}.pth')\n\n","metadata":{"id":"QxkC5a_lFOvA","outputId":"cb8c11e8-e6ba-42b5-ff27-d580e23ab481","papermill":{"duration":11747.786746,"end_time":"2023-12-19T20:44:40.200757","exception":false,"start_time":"2023-12-19T17:28:52.414011","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-08-01T06:51:27.079823Z","iopub.execute_input":"2024-08-01T06:51:27.080390Z","iopub.status.idle":"2024-08-01T06:51:27.136671Z","shell.execute_reply.started":"2024-08-01T06:51:27.080360Z","shell.execute_reply":"2024-08-01T06:51:27.135618Z"},"trusted":true},"execution_count":172,"outputs":[{"name":"stderr","text":"Epochs:   0%|          | 0/80 [00:00<?, ?it/s]\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[172], line 15\u001b[0m\n\u001b[1;32m     11\u001b[0m losses \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     13\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;66;03m# Start time of the epoch\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, (x,y) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[43mtrain_loader\u001b[49m):\n\u001b[1;32m     16\u001b[0m   x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mto(DEVICE)\n\u001b[1;32m     17\u001b[0m   y0, y1, y2 \u001b[38;5;241m=\u001b[39m (y[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mto(DEVICE),\n\u001b[1;32m     18\u001b[0m                 y[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mto(DEVICE),\n\u001b[1;32m     19\u001b[0m                 y[\u001b[38;5;241m2\u001b[39m]\u001b[38;5;241m.\u001b[39mto(DEVICE))\n","\u001b[0;31mNameError\u001b[0m: name 'train_loader' is not defined"],"ename":"NameError","evalue":"name 'train_loader' is not defined","output_type":"error"}]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nepochs = range(1, len(history_loss)+1)\n\n# Plot losses\nplt.plot(epochs, history_loss)\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Losses\")\nplt.title(\"Training Loss\")\nplt.show()","metadata":{"papermill":{"duration":0.331368,"end_time":"2023-12-19T20:44:40.554038","exception":false,"start_time":"2023-12-19T20:44:40.222670","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-08-01T06:50:50.705507Z","iopub.status.idle":"2024-08-01T06:50:50.705825Z","shell.execute_reply.started":"2024-08-01T06:50:50.705667Z","shell.execute_reply":"2024-08-01T06:50:50.705680Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Instantiate the model\nmodel = YOLOv3(num_classes=NUM_CLASSES).to(DEVICE)\n\n# Compile the model\noptimizer = torch.optim.Adam(\n    model.parameters(), lr=LEARNING_RATE\n)\nloss_fn = YoloLoss()\n\n# Scaler\nscaler = torch.cuda.amp.GradScaler()\n\n# Train-Test Loader\ntrain_loader, test_loader = get_loaders(\n    train_csv_path='/kaggle/input/pascalvoc-yolo/test.csv', test_csv_path='/kaggle/input/pascalvoc-yolo/test.csv'\n)\n\n# Anchors\nscaled_anchors = (\n    torch.tensor(ANCHORS) * torch.tensor([13,26,52]).unsqueeze(1).unsqueeze(1).repeat(1,3,2)\n).to(DEVICE)","metadata":{"papermill":{"duration":3.599173,"end_time":"2023-12-19T17:28:52.355790","exception":false,"start_time":"2023-12-19T17:28:48.756617","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-08-01T06:50:50.707008Z","iopub.status.idle":"2024-08-01T06:50:50.707378Z","shell.execute_reply.started":"2024-08-01T06:50:50.707201Z","shell.execute_reply":"2024-08-01T06:50:50.707218Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Inference","metadata":{"papermill":{"duration":0.024823,"end_time":"2023-12-19T20:44:40.602041","exception":false,"start_time":"2023-12-19T20:44:40.577218","status":"completed"},"tags":[]}},{"cell_type":"code","source":"model.eval()\nx, y = next(iter(test_loader))\nx = x.float().to(DEVICE)\n\nwith torch.no_grad():\n    out = model(x)\n    bboxes = [[] for _ in range(x.shape[0])]\n    batch_size, A, S, _, _ = out[0].shape\n    anchor = torch.tensor([*ANCHORS[0]]).to(DEVICE) * S\n    boxes_scale_i = cells_to_bboxes(\n        out[0], anchor, S=S, is_preds=True\n    )\n    for idx, (box) in enumerate(boxes_scale_i):\n        bboxes[idx] += box\n\n    for i in range(batch_size):\n        nms_boxes = non_max_suppression(\n            bboxes[i], iou_threshold=0.5, threshold=0.6, box_format=\"midpoint\",\n        )\n        plot_image(x[i].permute(1,2,0).detach().cpu(), nms_boxes)","metadata":{"papermill":{"duration":10.470574,"end_time":"2023-12-19T20:44:51.103637","exception":false,"start_time":"2023-12-19T20:44:40.633063","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-08-01T06:50:50.708383Z","iopub.status.idle":"2024-08-01T06:50:50.708680Z","shell.execute_reply.started":"2024-08-01T06:50:50.708529Z","shell.execute_reply":"2024-08-01T06:50:50.708541Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Testing","metadata":{"papermill":{"duration":0.15928,"end_time":"2023-12-19T20:44:51.430295","exception":false,"start_time":"2023-12-19T20:44:51.271015","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Load the model\nmodel = YOLOv3(num_classes=NUM_CLASSES)\nmodel_path = \"/kaggle/input/80-epoch-yolov3-model/Yolov3_epoch80.pth\"\nstate_dict = torch.load(model_path)\nmodel.load_state_dict(state_dict)\nmodel = model.to(DEVICE)\n\n# Testing\nlosses = []\n\nwith torch.no_grad():\n    model.eval()\n\n    for batch_idx, (x,y) in enumerate(test_loader):\n        x = x.to(DEVICE)\n        y0, y1, y2 = (y[0].to(DEVICE),\n                    y[1].to(DEVICE),\n                    y[2].to(DEVICE))\n\n        out = model(x)\n        loss = (\n            loss_fn(out[0], y0, scaled_anchors[0])\n            + loss_fn(out[1], y1, scaled_anchors[1])\n            + loss_fn(out[2], y2, scaled_anchors[2])\n        )\n\n        losses.append(loss.item())\n\nprint(f\"Loss: {sum(losses)/len(losses):.4f}\")","metadata":{"papermill":{"duration":119.671402,"end_time":"2023-12-19T20:46:51.245946","exception":false,"start_time":"2023-12-19T20:44:51.574544","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-08-01T06:50:50.709614Z","iopub.status.idle":"2024-08-01T06:50:50.709905Z","shell.execute_reply.started":"2024-08-01T06:50:50.709759Z","shell.execute_reply":"2024-08-01T06:50:50.709771Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred_boxes, true_boxes = get_evaluation_bboxes(\n                test_loader,\n                model,\n                iou_threshold=NMS_IOU_THRESH,\n                anchors=ANCHORS,\n                threshold=CONF_THRESHOLD,\n            )\n\nmapval = mean_average_precision(\n    pred_boxes,\n    true_boxes,\n    iou_threshold=MAP_IOU_THRESH,\n    box_format=\"midpoint\",\n    num_classes=NUM_CLASSES,\n)\nprint(f\"MAP: {mapval.item()}\")","metadata":{"papermill":{"duration":301.403008,"end_time":"2023-12-19T20:51:52.794895","exception":false,"start_time":"2023-12-19T20:46:51.391887","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-08-01T06:50:50.711364Z","iopub.status.idle":"2024-08-01T06:50:50.711680Z","shell.execute_reply.started":"2024-08-01T06:50:50.711524Z","shell.execute_reply":"2024-08-01T06:50:50.711537Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"papermill":{"duration":0.146697,"end_time":"2023-12-19T20:51:53.086209","exception":false,"start_time":"2023-12-19T20:51:52.939512","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]}]}