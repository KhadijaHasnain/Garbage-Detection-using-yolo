{"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["yjwnv6MYoEgc"],"gpuType":"T4","provenance":[]},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":1556326,"sourceType":"datasetVersion","datasetId":918769},{"sourceId":7240078,"sourceType":"datasetVersion","datasetId":4193279}],"dockerImageVersionId":30528,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"papermill":{"default_parameters":{},"duration":12211.677353,"end_time":"2023-12-19T20:51:56.359253","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2023-12-19T17:28:24.681900","version":"2.4.0"}},"nbformat_minor":5,"nbformat":4,"cells":[{"cell_type":"code","source":"# Imports\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as patches\nimport numpy as np\nimport os\n\nimport torch\n\nfrom collections import Counter\nfrom torch.utils.data import DataLoader\nfrom tqdm import tqdm","metadata":{"id":"qwgTtAyp3C7K","papermill":{"duration":4.058162,"end_time":"2023-12-19T17:28:39.273964","exception":false,"start_time":"2023-12-19T17:28:35.215802","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-08-02T13:27:37.518548Z","iopub.execute_input":"2024-08-02T13:27:37.519491Z","iopub.status.idle":"2024-08-02T13:27:37.525173Z","shell.execute_reply.started":"2024-08-02T13:27:37.519447Z","shell.execute_reply":"2024-08-02T13:27:37.524272Z"},"trusted":true},"execution_count":135,"outputs":[]},{"cell_type":"markdown","source":"# YOLO v3 model architecture","metadata":{"id":"yjwnv6MYoEgc","papermill":{"duration":0.011698,"end_time":"2023-12-19T17:28:39.297965","exception":false,"start_time":"2023-12-19T17:28:39.286267","status":"completed"},"tags":[]}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\n\nconfig = [\n    (32, 3, 1),\n    (128, 3, 1),  # New layer added here\n    (64, 3, 2),\n    [\"list\", 1],\n    (128, 3, 2),\n    [\"list\", 2],\n    (256, 3, 2),\n    [\"list\", 8],\n    (512, 3, 2),\n    [\"list\", 8],\n    (1024, 3, 2),\n    [\"list\", 4],  # To this point is Darknet-53\n\n    (512, 1, 1),\n    (1024, 3, 1),\n    \"sp\",\n    (256, 1, 1),\n    \"up\",\n    (256, 1, 1),\n    (512, 3, 1),\n    \"sp\",\n    (128, 1, 1),\n    \"up\",\n    (128, 1, 1),\n    (256, 3, 1),\n    \"sp\",\n]\n","metadata":{"id":"zs0uKuG55xC_","papermill":{"duration":0.022597,"end_time":"2023-12-19T17:28:39.332406","exception":false,"start_time":"2023-12-19T17:28:39.309809","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-08-02T13:27:37.538895Z","iopub.execute_input":"2024-08-02T13:27:37.539404Z","iopub.status.idle":"2024-08-02T13:27:37.546669Z","shell.execute_reply.started":"2024-08-02T13:27:37.539367Z","shell.execute_reply":"2024-08-02T13:27:37.545728Z"},"trusted":true},"execution_count":136,"outputs":[]},{"cell_type":"code","source":"class CNN_Block(nn.Module):\n  def __init__(self, in_channels, out_channels, bn_act=True, **kwargs):\n    super(CNN_Block, self).__init__()\n    self.conv = nn.Conv2d(in_channels, out_channels, bias=not bn_act, **kwargs) # If batchnorm layer(bn_act) is true, then bias is False\n    self.bn = nn.BatchNorm2d(out_channels)\n    self.leaky = nn.LeakyReLU(0.1)\n    self.use_bn_act = bn_act\n\n  def forward(self, x):\n    if self.use_bn_act:\n      return self.leaky(self.bn(self.conv(x)))\n    else:\n      return self.conv(x)\n\n\nclass Residual_Block(nn.Module):\n  def __init__(self, channels, use_residual=True, num_repeats=1):\n    super(Residual_Block, self).__init__()\n    self.layers = nn.ModuleList() # Like regular python list, but is container for pytorch nn modules\n\n    for repeat in range(num_repeats):\n      self.layers += [\n          nn.Sequential(\n            CNN_Block(channels, channels//2, kernel_size=1),\n            CNN_Block(channels//2, channels, kernel_size=3, padding=1)\n          )\n      ]\n\n    self.use_residual = use_residual\n    self.num_repeats = num_repeats\n\n  def forward(self, x):\n    for layer in self.layers:\n      if self.use_residual:\n        x = x + layer(x)\n      else:\n        x = layer(x)\n\n    return x","metadata":{"id":"Q_zaXn4YQCl7","papermill":{"duration":0.02402,"end_time":"2023-12-19T17:28:39.368315","exception":false,"start_time":"2023-12-19T17:28:39.344295","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-08-02T13:27:37.597433Z","iopub.execute_input":"2024-08-02T13:27:37.597732Z","iopub.status.idle":"2024-08-02T13:27:37.607992Z","shell.execute_reply.started":"2024-08-02T13:27:37.597706Z","shell.execute_reply":"2024-08-02T13:27:37.606896Z"},"trusted":true},"execution_count":137,"outputs":[]},{"cell_type":"code","source":"class Prediction_Scale(nn.Module):\n  def __init__(self, in_channels, NumClasses):\n    super(Prediction_Scale, self).__init__()\n    self.pred = nn.Sequential(\n        CNN_Block(in_channels, 2 * in_channels, kernel_size=3, padding=1),\n        CNN_Block(2 * in_channels, (NumClasses + 5) * 3, bn_act=False, kernel_size=1), # (NumClasses + 5) * 3 --> (20+5) for each anchor box which in total is 3\n    )\n    self.NumClasses = NumClasses\n\n  def forward(self, x):\n    return (\n        self.pred(x)\n        .reshape(x.shape[0], 3, self.NumClasses + 5, x.shape[2], x.shape[3]) # [batch_size, anchor_boxes, prediction(25), grid_h, grid_w]\n        .permute(0, 1, 3, 4, 2) # [batch_size, anchor_boxes, grid_h, grid_w, prediction(25)]\n      )","metadata":{"id":"IUrOUQNeXDcG","papermill":{"duration":0.021337,"end_time":"2023-12-19T17:28:39.401877","exception":false,"start_time":"2023-12-19T17:28:39.380540","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-08-02T13:27:37.609590Z","iopub.execute_input":"2024-08-02T13:27:37.609914Z","iopub.status.idle":"2024-08-02T13:27:37.618357Z","shell.execute_reply.started":"2024-08-02T13:27:37.609881Z","shell.execute_reply":"2024-08-02T13:27:37.617493Z"},"trusted":true},"execution_count":138,"outputs":[]},{"cell_type":"code","source":"class YOLOv3(nn.Module):\n  def __init__(self, in_channels=3, NumClasses=20):\n    super(YOLOv3, self).__init__()\n    self.NumClasses = NumClasses\n    self.in_channels = in_channels\n    self.layers = self._create_conv_layers()\n\n  def forward(self, x):\n    outputs = []\n    route_connections = []\n\n    for layer in self.layers:\n      if isinstance(layer, Prediction_Scale):\n        outputs.append(layer(x))\n        continue\n\n      x = layer(x)\n\n      if isinstance(layer, Residual_Block) and layer.num_repeats == 8:\n        route_connections.append(x)\n\n      elif isinstance(layer, nn.Upsample):\n        x = torch.cat([x, route_connections[-1]], dim=1)\n        route_connections.pop()\n\n    return outputs\n\n  def _create_conv_layers(self):\n    layers = nn.ModuleList()\n    in_channels = self.in_channels\n\n    for module in config:\n      if isinstance(module, tuple):\n        out_channels, kernel_size, stride = module\n        layers.append(CNN_Block(\n            in_channels,\n            out_channels,\n            kernel_size=kernel_size,\n            stride=stride,\n            padding=1 if kernel_size == 3 else 0\n        ))\n        in_channels = out_channels\n\n      elif isinstance(module, list):\n        num_repeats = module[1]\n        layers.append(Residual_Block(in_channels, num_repeats=num_repeats))\n\n      elif isinstance(module, str):\n        if module == \"sp\":\n          layers += [\n              Residual_Block(in_channels, use_residual=False, num_repeats=1),\n              CNN_Block(in_channels, in_channels//2, kernel_size=1),\n              Prediction_Scale(in_channels//2, NumClasses = self.NumClasses)\n          ]\n          in_channels = in_channels // 2\n\n        elif module == \"up\":\n          layers.append(nn.Upsample(scale_factor=2))\n          in_channels = in_channels * 3\n\n    return layers\n","metadata":{"id":"iwYyoG0AQXtj","papermill":{"duration":0.026458,"end_time":"2023-12-19T17:28:39.440149","exception":false,"start_time":"2023-12-19T17:28:39.413691","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-08-02T13:27:37.636948Z","iopub.execute_input":"2024-08-02T13:27:37.637232Z","iopub.status.idle":"2024-08-02T13:27:37.649330Z","shell.execute_reply.started":"2024-08-02T13:27:37.637209Z","shell.execute_reply":"2024-08-02T13:27:37.648407Z"},"trusted":true},"execution_count":139,"outputs":[]},{"cell_type":"code","source":"NumClasses = 20\nImageSize = 416\nmodel = YOLOv3(NumClasses=NumClasses)\nx = torch.randn((2, 3, ImageSize, ImageSize))\nout = model(x)\nassert model(x)[0].shape == (2, 3, ImageSize//32, ImageSize//32, NumClasses + 5)\nassert model(x)[1].shape == (2, 3, ImageSize//16, ImageSize//16, NumClasses + 5)\nassert model(x)[2].shape == (2, 3, ImageSize//8, ImageSize//8, NumClasses + 5)\nprint(\"Success!\")","metadata":{"id":"-S2pyv5SmViF","outputId":"a24522a5-0211-475d-8154-518fbcf6d0e5","papermill":{"duration":4.867126,"end_time":"2023-12-19T17:28:44.318961","exception":false,"start_time":"2023-12-19T17:28:39.451835","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-08-02T13:27:37.651269Z","iopub.execute_input":"2024-08-02T13:27:37.651777Z","iopub.status.idle":"2024-08-02T13:27:42.579403Z","shell.execute_reply.started":"2024-08-02T13:27:37.651740Z","shell.execute_reply":"2024-08-02T13:27:42.578403Z"},"trusted":true},"execution_count":140,"outputs":[{"name":"stdout","text":"Success!\n","output_type":"stream"}]},{"cell_type":"code","source":"# Count the total trainable parameters\nParamsTotal = sum(p.numel() for p in model.parameters() if p.requires_grad)\nprint(f\"Total trainable parameters: {ParamsTotal}\")","metadata":{"papermill":{"duration":0.022954,"end_time":"2023-12-19T17:28:47.230899","exception":false,"start_time":"2023-12-19T17:28:47.207945","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-08-02T13:27:42.581447Z","iopub.execute_input":"2024-08-02T13:27:42.582001Z","iopub.status.idle":"2024-08-02T13:27:42.590835Z","shell.execute_reply.started":"2024-08-02T13:27:42.581965Z","shell.execute_reply":"2024-08-02T13:27:42.589662Z"},"trusted":true},"execution_count":141,"outputs":[{"name":"stdout","text":"Total trainable parameters: 61718915\n","output_type":"stream"}]},{"cell_type":"code","source":"def WeidthHeight(boxa, boxb):\n    \n    intersection = torch.min(boxa[..., 0], boxb[..., 0]) * torch.min(\n        boxa[..., 1], boxb[..., 1]\n    )\n    union = (\n        boxa[..., 0] * boxa[..., 1] + boxb[..., 0] * boxb[..., 1] - intersection\n    )\n    return intersection / union","metadata":{"id":"4P448jivxbnu","papermill":{"duration":0.021393,"end_time":"2023-12-19T17:28:47.701182","exception":false,"start_time":"2023-12-19T17:28:47.679789","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-08-02T13:27:42.592189Z","iopub.execute_input":"2024-08-02T13:27:42.592467Z","iopub.status.idle":"2024-08-02T13:27:42.603104Z","shell.execute_reply.started":"2024-08-02T13:27:42.592442Z","shell.execute_reply":"2024-08-02T13:27:42.602066Z"},"trusted":true},"execution_count":142,"outputs":[]},{"cell_type":"code","source":"def InterctionOverUnion(PredsBox, lableBox, box_format=\"midpoint\"):\n\n    if box_format == \"midpoint\":\n        box1_a1 = PredsBox[..., 0:1] - PredsBox[..., 2:3] / 2\n        box1_b1 = PredsBox[..., 1:2] - PredsBox[..., 3:4] / 2\n        box1_a2 = PredsBox[..., 0:1] + PredsBox[..., 2:3] / 2\n        box1_b2 = PredsBox[..., 1:2] + PredsBox[..., 3:4] / 2\n        box2_a1 = lableBox[..., 0:1] - lableBox[..., 2:3] / 2\n        box2_y1 = lableBox[..., 1:2] - lableBox[..., 3:4] / 2\n        box2_a2 = lableBox[..., 0:1] + lableBox[..., 2:3] / 2\n        box2_y2 = lableBox[..., 1:2] + lableBox[..., 3:4] / 2\n\n    if box_format == \"corners\":\n        box1_a1 = PredsBox[..., 0:1]\n        box1_b1 = PredsBox[..., 1:2]\n        box1_a2 = PredsBox[..., 2:3]\n        box1_b2 = PredsBox[..., 3:4]\n        box2_a1 = lableBox[..., 0:1]\n        box2_y1 = lableBox[..., 1:2]\n        box2_a2 = lableBox[..., 2:3]\n        box2_y2 = lableBox[..., 3:4]\n\n    x1 = torch.max(box1_a1, box2_a1)\n    y1 = torch.max(box1_b1, box2_y1)\n    x2 = torch.min(box1_a2, box2_a2)\n    y2 = torch.min(box1_b2, box2_y2)\n\n    intersection = (x2 - x1).clamp(0) * (y2 - y1).clamp(0)\n    box1_area = abs((box1_a2 - box1_a1) * (box1_b2 - box1_b1))\n    box2_area = abs((box2_a2 - box2_a1) * (box2_y2 - box2_y1))\n\n    return intersection / (box1_area + box2_area - intersection + 1e-6)","metadata":{"id":"RvwUplkYxqrw","papermill":{"duration":0.027159,"end_time":"2023-12-19T17:28:47.766138","exception":false,"start_time":"2023-12-19T17:28:47.738979","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-08-02T13:27:42.605467Z","iopub.execute_input":"2024-08-02T13:27:42.605739Z","iopub.status.idle":"2024-08-02T13:27:42.617586Z","shell.execute_reply.started":"2024-08-02T13:27:42.605714Z","shell.execute_reply":"2024-08-02T13:27:42.616698Z"},"trusted":true},"execution_count":143,"outputs":[]},{"cell_type":"code","source":"def non_max_suppression(boxx, iou_threshold, threshold, box_format=\"corners\"):\n   \n    assert type(boxx) == list\n\n    boxx = [box for box in boxx if box[1] > threshold]\n    boxx = sorted(boxx, key=lambda x: x[1], reverse=True)\n    boxx_after_nms = []\n\n    while boxx:\n        chosen_box = boxx.pop(0)\n\n        boxx = [\n            box\n            for box in boxx\n            if box[0] != chosen_box[0]\n            or InterctionOverUnion(\n                torch.tensor(chosen_box[2:]),\n                torch.tensor(box[2:]),\n                box_format=box_format,\n            )\n            < iou_threshold\n        ]\n\n        boxx_after_nms.append(chosen_box)\n\n    return boxx_after_nms","metadata":{"id":"0oIq_NZpxzNi","papermill":{"duration":0.022558,"end_time":"2023-12-19T17:28:47.827509","exception":false,"start_time":"2023-12-19T17:28:47.804951","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-08-02T13:27:42.618823Z","iopub.execute_input":"2024-08-02T13:27:42.619192Z","iopub.status.idle":"2024-08-02T13:27:42.635233Z","shell.execute_reply.started":"2024-08-02T13:27:42.619160Z","shell.execute_reply":"2024-08-02T13:27:42.634375Z"},"trusted":true},"execution_count":144,"outputs":[]},{"cell_type":"markdown","source":"# Dataset","metadata":{"id":"6qWub9xCoJQP","papermill":{"duration":0.012761,"end_time":"2023-12-19T17:28:47.853131","exception":false,"start_time":"2023-12-19T17:28:47.840370","status":"completed"},"tags":[]}},{"cell_type":"code","source":"import numpy as np\nimport os\nimport pandas as pd\nimport torch\n\nfrom torch.utils.data import Dataset, DataLoader\nfrom PIL import Image, ImageFile","metadata":{"id":"17VUsG5An6ED","papermill":{"duration":0.019761,"end_time":"2023-12-19T17:28:47.885721","exception":false,"start_time":"2023-12-19T17:28:47.865960","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-08-02T13:27:42.636369Z","iopub.execute_input":"2024-08-02T13:27:42.636709Z","iopub.status.idle":"2024-08-02T13:27:42.647519Z","shell.execute_reply.started":"2024-08-02T13:27:42.636675Z","shell.execute_reply":"2024-08-02T13:27:42.646714Z"},"trusted":true},"execution_count":145,"outputs":[]},{"cell_type":"code","source":"# allows PIL to load images even if they are truncated or incomplete\nImageFile.LOAD_TRUNCATED_IMAGES = True","metadata":{"id":"Lfov94HNpy4C","papermill":{"duration":0.018826,"end_time":"2023-12-19T17:28:47.917203","exception":false,"start_time":"2023-12-19T17:28:47.898377","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-08-02T13:27:42.649021Z","iopub.execute_input":"2024-08-02T13:27:42.649382Z","iopub.status.idle":"2024-08-02T13:27:42.662819Z","shell.execute_reply.started":"2024-08-02T13:27:42.649349Z","shell.execute_reply":"2024-08-02T13:27:42.662147Z"},"trusted":true},"execution_count":146,"outputs":[]},{"cell_type":"code","source":"class YOLODataset(Dataset):\n  def __init__(self, csv_file, ImgDir, LableDir, anchors,\n               ImageSize=416, sp=[13,26,52], cp=20, transform=None):\n    self.annotations = pd.read_csv(csv_file)\n    self.ImgDir = ImgDir\n    self.LableDir = LableDir\n    self.transform = transform\n    self.sp = sp\n\n    self.anchors = torch.tensor(anchors[0] + anchors[1] + anchors[2]) # For all 3 scales\n    self.num_anchors = self.anchors.shape[0]\n    self.num_anchors_per_scale = self.num_anchors // 3\n\n    self.cp = cp\n\n    self.ignore_iou_thresh = 0.5\n\n  def __len__(self):\n    return len(self.annotations)\n\n  def __getitem__(self, index):\n    label_path = os.path.join(self.LableDir, self.annotations.iloc[index, 1])\n    boxx = np.roll(np.loadtxt(fname=label_path, delimiter=\" \", ndmin=2), 4, axis=1).tolist() # np.roll with shift 4 on axis 1: [class, x, y, w, h] --> [x, y, w, h, class]\n\n    img_path = os.path.join(self.ImgDir, self.annotations.iloc[index, 0])\n    image = Image.open(img_path)\n\n    if self.transform:\n      image = self.transform(image)\n\n    targets = [torch.zeros((self.num_anchors // 3, sp, sp, 6)) for sp in self.sp] # 6 because objectness score, bounding box coordinates (x, y, w, h), class label\n\n    for box in boxx:\n      iou_anchors = WeidthHeight(torch.tensor(box[2:4]), self.anchors) # IOU from height and width\n      anchor_indices = iou_anchors.argsort(descending=True, dim=0) # Sorting sucht that the first is the best anchor\n\n      x, y, width, height, class_label = box\n      has_anchor = [False, False, False] # Make sure there is an anchor for each of three scales for each bounding box\n\n      for anchor_idx in anchor_indices:\n        scale_idx = anchor_idx // self.num_anchors_per_scale # scale_idx is either 0,1,2: 0-->13x13, 1:-->26x26, 2:-->52x52\n        anchor_on_scale = anchor_idx % self.num_anchors_per_scale # In each scale, choosing the anchor thats either 0,1,2\n\n        sp = self.sp[scale_idx]\n        i, j = int(sp*y), int(sp*x) # x=0.5, sp=13 --> int(6.5) = 6 | i=y cell, j=x cell\n        anchor_taken = targets[scale_idx][anchor_on_scale, i, j, 0]\n\n        if not anchor_taken and not has_anchor[scale_idx]:\n          targets[scale_idx][anchor_on_scale, i, j, 0] = 1\n          x_cell, y_cell = sp*x - j, sp*y - i # 6.5 - 6 = 0.5 such that they are between [0,1]\n          width_cell, height_cell = (\n              width*sp, # sp=13, width=0.5, 6.5\n              height*sp\n          )\n\n          box_coordinates = torch.tensor([x_cell, y_cell, width_cell, height_cell])\n\n          targets[scale_idx][anchor_on_scale, i, j, 1:5] = box_coordinates\n          targets[scale_idx][anchor_on_scale, i, j, 5] = int(class_label)\n          has_anchor[scale_idx] = True\n\n        # Even if the same grid shares another anchor having iou>ignore_iou_thresh then,\n        elif not anchor_taken and iou_anchors[anchor_idx] > self.ignore_iou_thresh:\n          targets[scale_idx][anchor_on_scale, i, j, 0] = -1 # ignore this prediction\n\n    return image, tuple(targets)\n","metadata":{"id":"UiM8IiJeqIV4","papermill":{"duration":0.031674,"end_time":"2023-12-19T17:28:47.961698","exception":false,"start_time":"2023-12-19T17:28:47.930024","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-08-02T13:27:42.664193Z","iopub.execute_input":"2024-08-02T13:27:42.664538Z","iopub.status.idle":"2024-08-02T13:27:42.680713Z","shell.execute_reply.started":"2024-08-02T13:27:42.664503Z","shell.execute_reply":"2024-08-02T13:27:42.680000Z"},"trusted":true},"execution_count":147,"outputs":[]},{"cell_type":"code","source":"import torchvision.transforms as transforms\ntransform = transforms.Compose([transforms.Resize((416, 416)), transforms.ToTensor()])","metadata":{"id":"BsljMXYuXndg","papermill":{"duration":0.325693,"end_time":"2023-12-19T17:28:48.326146","exception":false,"start_time":"2023-12-19T17:28:48.000453","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-08-02T13:27:42.681786Z","iopub.execute_input":"2024-08-02T13:27:42.682116Z","iopub.status.idle":"2024-08-02T13:27:42.697755Z","shell.execute_reply.started":"2024-08-02T13:27:42.682076Z","shell.execute_reply":"2024-08-02T13:27:42.696753Z"},"trusted":true},"execution_count":148,"outputs":[]},{"cell_type":"code","source":"def get_loaders(train_csv_path, test_csv_path):\n\n    train_dataset = YOLODataset(\n        train_csv_path,\n        transform=transform,\n        sp=[ImageSize // 32, ImageSize // 16, ImageSize // 8],\n        ImgDir=DirImage,\n        LableDir=DirLable,\n        anchors=ANCHORS,\n    )\n    test_dataset = YOLODataset(\n        test_csv_path,\n        transform=transform,\n        sp=[ImageSize // 32, ImageSize // 16, ImageSize // 8],\n        ImgDir=DirImage,\n        LableDir=DirLable,\n        anchors=ANCHORS,\n    )\n    train_loader = DataLoader(\n        dataset=train_dataset,\n        batch_size=SizeOfBatch,\n        shuffle=True,\n        drop_last=False,\n    )\n    test_loader = DataLoader(\n        dataset=test_dataset,\n        batch_size=SizeOfBatch,\n        shuffle=False,\n        drop_last=False,\n    )\n\n    return train_loader, test_loader","metadata":{"id":"10SzzqKdzExo","papermill":{"duration":0.028829,"end_time":"2023-12-19T17:28:48.374519","exception":false,"start_time":"2023-12-19T17:28:48.345690","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-08-02T13:27:42.700836Z","iopub.execute_input":"2024-08-02T13:27:42.701138Z","iopub.status.idle":"2024-08-02T13:27:42.709321Z","shell.execute_reply.started":"2024-08-02T13:27:42.701114Z","shell.execute_reply":"2024-08-02T13:27:42.708527Z"},"trusted":true},"execution_count":149,"outputs":[]},{"cell_type":"code","source":"def mean_average_precision(\n    pred_boxes, true_boxes, iou_threshold=0.5, box_format=\"midpoint\", NumClasses=4\n):\n\n    # list storing all AP for respective classes\n    average_precisions = []\n\n    # used for numerical stability later on\n    epsilon = 1e-6\n\n    for c in range(NumClasses):\n        detections = []\n        ground_truths = []\n\n        for detection in pred_boxes:\n            if detection[1] == c:\n                detections.append(detection)\n\n        for true_box in true_boxes:\n            if true_box[1] == c:\n                ground_truths.append(true_box)\n\n        amount_boxx = Counter([gt[0] for gt in ground_truths])\n\n        for key, val in amount_boxx.items():\n            amount_boxx[key] = torch.zeros(val)\n\n        # sort by box probabilities which is index 2\n        detections.sort(key=lambda x: x[2], reverse=True)\n        TP = torch.zeros((len(detections)))\n        FP = torch.zeros((len(detections)))\n        total_true_boxx = len(ground_truths)\n\n        # If none exists for this class then we can safely skip\n        if total_true_boxx == 0:\n            continue\n\n        for detection_idx, detection in enumerate(detections):\n            ground_truth_img = [\n                bbox for bbox in ground_truths if bbox[0] == detection[0]\n            ]\n\n            num_gts = len(ground_truth_img)\n            best_iou = 0\n\n            for idx, gt in enumerate(ground_truth_img):\n                iou = InterctionOverUnion(\n                    torch.tensor(detection[3:]),\n                    torch.tensor(gt[3:]),\n                    box_format=box_format,\n                )\n\n                if iou > best_iou:\n                    best_iou = iou\n                    best_gt_idx = idx\n\n            if best_iou > iou_threshold:\n                # only detect ground truth detection once\n                if amount_boxx[detection[0]][best_gt_idx] == 0:\n                    # true positive and add this bounding box to seen\n                    TP[detection_idx] = 1\n                    amount_boxx[detection[0]][best_gt_idx] = 1\n                else:\n                    FP[detection_idx] = 1\n\n            # if IOU is lower then the detection is a false positive\n            else:\n                FP[detection_idx] = 1\n\n        TP_cumsum = torch.cumsum(TP, dim=0)\n        FP_cumsum = torch.cumsum(FP, dim=0)\n        recalls = TP_cumsum / (total_true_boxx + epsilon)\n        precisions = TP_cumsum / (TP_cumsum + FP_cumsum + epsilon)\n        precisions = torch.cat((torch.tensor([1]), precisions))\n        recalls = torch.cat((torch.tensor([0]), recalls))\n        # torch.trapz for numerical integration\n        average_precisions.append(torch.trapz(precisions, recalls))\n\n    return sum(average_precisions) / len(average_precisions)","metadata":{"papermill":{"duration":0.032317,"end_time":"2023-12-19T17:28:48.448856","exception":false,"start_time":"2023-12-19T17:28:48.416539","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-08-02T13:27:42.710536Z","iopub.execute_input":"2024-08-02T13:27:42.710872Z","iopub.status.idle":"2024-08-02T13:27:42.727514Z","shell.execute_reply.started":"2024-08-02T13:27:42.710840Z","shell.execute_reply":"2024-08-02T13:27:42.726814Z"},"trusted":true},"execution_count":150,"outputs":[]},{"cell_type":"code","source":"def get_evaluation_boxx(\n    loader,\n    model,\n    iou_threshold,\n    anchors,\n    threshold,\n    box_format=\"midpoint\",\n    device=\"cuda\" if torch.cuda.is_available() else \"cpu\",\n):\n    # make sure model is in eval before get boxx\n    model.eval()\n    train_idx = 0\n    all_pred_boxes = []\n    all_true_boxes = []\n    for batch_idx, (x, labels) in enumerate(loader):\n        x = x.float().to(device)\n\n        with torch.no_grad():\n            predictions = model(x)\n\n        batch_size = x.shape[0]\n        boxx = [[] for _ in range(batch_size)]\n        for i in range(3):\n            sp = predictions[i].shape[2] # grid cell size for each predictions\n            anchor = torch.tensor([*anchors[i]]).to(device) * sp # anchor for each grid, prediction type\n            boxes_scale_i = cells_to_boxx( # get boxx for each image in the batch\n                predictions[i], anchor, sp=sp, is_preds=True\n            )\n            for idx, (box) in enumerate(boxes_scale_i): # for each image, append the bbox to corr. boxx[idx]\n                boxx[idx] += box\n\n        # we just want one bbox for each label, not one for each scale\n        true_boxx = cells_to_boxx(\n            labels[2], anchor, sp=sp, is_preds=False\n        )\n\n        for idx in range(batch_size):\n            nms_boxes = non_max_suppression(\n                boxx[idx],\n                iou_threshold=iou_threshold,\n                threshold=threshold,\n                box_format=box_format,\n            )\n\n            for nms_box in nms_boxes:\n                all_pred_boxes.append([train_idx] + nms_box)\n\n            for box in true_boxx[idx]:\n                if box[1] > threshold:\n                    all_true_boxes.append([train_idx] + box)\n\n            train_idx += 1\n\n    model.train()\n    return all_pred_boxes, all_true_boxes","metadata":{"papermill":{"duration":0.034433,"end_time":"2023-12-19T17:28:48.529102","exception":false,"start_time":"2023-12-19T17:28:48.494669","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-08-02T13:27:42.728466Z","iopub.execute_input":"2024-08-02T13:27:42.728723Z","iopub.status.idle":"2024-08-02T13:27:42.745967Z","shell.execute_reply.started":"2024-08-02T13:27:42.728699Z","shell.execute_reply":"2024-08-02T13:27:42.745125Z"},"trusted":true},"execution_count":151,"outputs":[]},{"cell_type":"code","source":"import cv2\nimport torch\n\nDEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\nWorkersNo = 4\nSizeOfBatch = 32\nImageSize = 416\nClassesNo = 20\nRateOfLearning = 1e-5\nEpochsNo = 80\nThresholdConf = 0.8\nThreshMap = 0.5\nThreshNms = 0.45\nsp = [ImageSize // 32, ImageSize // 16, ImageSize // 8]\n\nDirImage = \"/kaggle/input/pascalvoc-yolo/images\"\nDirLable = \"/kaggle/input/pascalvoc-yolo/labels\"\n\nANCHORS = [\n    [(0.28, 0.22), (0.38, 0.48), (0.9, 0.78)],\n    [(0.07, 0.15), (0.15, 0.11), (0.14, 0.29)],\n    [(0.02, 0.03), (0.04, 0.07), (0.08, 0.06)],\n] \n\n\nAllClacess = [\n    \"aeroplane\",\n    \"bicycle\",\n    \"bird\",\n    \"boat\",\n    \"bottle\",\n    \"bus\",\n    \"car\",\n    \"cat\",\n    \"chair\",\n    \"cow\",\n    \"diningtable\",\n    \"dog\",\n    \"horse\",\n    \"motorbike\",\n    \"person\",\n    \"pottedplant\",\n    \"sheep\",\n    \"sofa\",\n    \"train\",\n    \"tvmonitor\"\n]","metadata":{"id":"9Ai7PMaUteOY","papermill":{"duration":0.371109,"end_time":"2023-12-19T17:28:47.640461","exception":false,"start_time":"2023-12-19T17:28:47.269352","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-08-02T13:27:42.747065Z","iopub.execute_input":"2024-08-02T13:27:42.747322Z","iopub.status.idle":"2024-08-02T13:27:42.761311Z","shell.execute_reply.started":"2024-08-02T13:27:42.747299Z","shell.execute_reply":"2024-08-02T13:27:42.760555Z"},"trusted":true},"execution_count":152,"outputs":[]},{"cell_type":"code","source":"def cells_to_boxx(predictions, anchors, sp, is_preds=True):\n\n    SizeOfBatch = predictions.shape[0]\n    num_anchors = len(anchors)\n    box_predictions = predictions[..., 1:5]\n    if is_preds:\n        anchors = anchors.reshape(1, len(anchors), 1, 1, 2)\n        box_predictions[..., 0:2] = torch.sigmoid(box_predictions[..., 0:2])\n        box_predictions[..., 2:] = torch.exp(box_predictions[..., 2:]) * anchors\n        scores = torch.sigmoid(predictions[..., 0:1])\n        best_class = torch.argmax(predictions[..., 5:], dim=-1).unsqueeze(-1)\n    else:\n        scores = predictions[..., 0:1]\n        best_class = predictions[..., 5:6]\n\n    cell_indices = (\n        torch.arange(sp)\n        .repeat(predictions.shape[0], 3, sp, 1)\n        .unsqueeze(-1)\n        .to(predictions.device)\n    )\n    x = 1 / sp * (box_predictions[..., 0:1] + cell_indices)\n    y = 1 / sp * (box_predictions[..., 1:2] + cell_indices.permute(0, 1, 3, 2, 4))\n    w_h = 1 / sp * box_predictions[..., 2:4]\n    converted_boxx = torch.cat((best_class, scores, x, y, w_h), dim=-1).reshape(SizeOfBatch, num_anchors * sp * sp, 6)\n    return converted_boxx.tolist()","metadata":{"papermill":{"duration":0.029879,"end_time":"2023-12-19T17:28:48.576674","exception":false,"start_time":"2023-12-19T17:28:48.546795","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-08-02T13:27:42.762227Z","iopub.execute_input":"2024-08-02T13:27:42.762460Z","iopub.status.idle":"2024-08-02T13:27:42.778130Z","shell.execute_reply.started":"2024-08-02T13:27:42.762439Z","shell.execute_reply":"2024-08-02T13:27:42.777276Z"},"trusted":true},"execution_count":153,"outputs":[]},{"cell_type":"markdown","source":"# Loss","metadata":{"id":"BlYBUIFvh9yd","papermill":{"duration":0.012777,"end_time":"2023-12-19T17:28:48.602300","exception":false,"start_time":"2023-12-19T17:28:48.589523","status":"completed"},"tags":[]}},{"cell_type":"code","source":"class YoloLoss(nn.Module):\n  def __init__(self):\n    super(YoloLoss, self).__init__()\n    self.mse = nn.MSELoss() # For bounding box loss\n    self.bce = nn.BCEWithLogitsLoss() # For multi-label prediction: Binary cross entropy\n    self.entropy = nn.CrossEntropyLoss() # For classification\n    self.sigmoid = nn.Sigmoid()\n\n    # Constants for significance of obj, or no obj.\n    self.lambda_class = 1\n    self.lambda_noobj = 10\n    self.lambda_obj = 1\n    self.lambda_box = 10\n\n  def forward(self, predictions, target, anchors):\n    obj = target[..., 0] == 1\n    noobj = target[..., 0] == 0\n\n    no_object_loss = self.bce(\n        (predictions[..., 0:1][noobj]), (target[..., 0:1][noobj])\n    )\n\n    anchors = anchors.reshape(1,3,1,1,2) # Anchors initial shape 3x2 --> 3 anchor boxes each of certain hxw (2)\n\n    # box_preds = [..., sigmoid(x), sigmoid(y), [p_w * exp(t_w)], [p_h * exp(t_h)], ...]\n    box_preds = torch.cat([self.sigmoid(predictions[..., 1:3]), torch.exp(predictions[..., 3:5]) * anchors], dim=-1)\n\n    # iou between predicted box and target box\n    ious = InterctionOverUnion(box_preds[obj], target[..., 1:5][obj]).detach()\n\n    object_loss = self.bce(\n        (predictions[..., 0:1][obj]), (ious * target[..., 0:1][obj]) # target * iou because only intersected part object loss calc\n    )\n\n    predictions[..., 1:3] = self.sigmoid(predictions[..., 1:3]) # x, y to be between [0,1]\n    target[..., 3:5] = torch.log(\n        (1e-6 + target[..., 3:5] / anchors)\n    ) # Exponential of hxw (taking log because opp. of exp)\n\n    box_loss = self.mse(predictions[..., 1:5][obj], target[..., 1:5][obj])\n\n    class_loss = self.entropy(\n        (predictions[..., 5:][obj]), (target[..., 5][obj].long())\n    )\n\n    return(\n        self.lambda_box * box_loss\n        + self.lambda_obj * object_loss\n        + self.lambda_noobj * no_object_loss\n        + self.lambda_class * class_loss\n    )\n","metadata":{"id":"i5nJTWLRiAY1","papermill":{"duration":0.032184,"end_time":"2023-12-19T17:28:48.648025","exception":false,"start_time":"2023-12-19T17:28:48.615841","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-08-02T13:27:42.779375Z","iopub.execute_input":"2024-08-02T13:27:42.779640Z","iopub.status.idle":"2024-08-02T13:27:42.792308Z","shell.execute_reply.started":"2024-08-02T13:27:42.779615Z","shell.execute_reply":"2024-08-02T13:27:42.791283Z"},"trusted":true},"execution_count":154,"outputs":[]},{"cell_type":"markdown","source":"# Plot Image","metadata":{"id":"M2mlDBxU2pjJ","papermill":{"duration":0.012422,"end_time":"2023-12-19T17:28:48.673454","exception":false,"start_time":"2023-12-19T17:28:48.661032","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def plot_image(image, boxes):\n    \"\"\"Plots predicted bounding boxes on the image\"\"\"\n    cmap = plt.get_cmap(\"tab20b\")\n    class_labels = AllClacess\n    colors = [cmap(i) for i in np.linspace(0, 1, len(class_labels))]\n    im = np.array(image)\n    height, width, _ = im.shape\n\n    # Create figure and axes\n    fig, ax = plt.subplots(1)\n    # Display the image\n    ax.imshow(im)\n\n    # Create a Rectangle patch\n    for box in boxes:\n        assert len(box) == 6, \"box should contain class pred, confidence, x, y, width, height\"\n        class_pred = box[0]\n        box = box[2:]\n        UpperLeft_x = box[0] - box[2] / 2\n        UpperLeft_y = box[1] - box[3] / 2\n        rect = patches.Rectangle(\n            (UpperLeft_x * width, UpperLeft_y * height),\n            box[2] * width,\n            box[3] * height,\n            linewidth=2,\n            edgecolor=colors[int(class_pred)],\n            facecolor=\"none\",\n        )\n        # Add the patch to the Axes\n        ax.add_patch(rect)\n        plt.text(\n            UpperLeft_x * width,\n            UpperLeft_y * height,\n            s=class_labels[int(class_pred)],\n            color=\"white\",\n            verticalalignment=\"top\",\n            bbox={\"color\": colors[int(class_pred)], \"pad\": 0},\n        )\n\n    plt.show()","metadata":{"id":"Xjl_AldR2rX9","papermill":{"duration":0.02615,"end_time":"2023-12-19T17:28:48.712437","exception":false,"start_time":"2023-12-19T17:28:48.686287","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-08-02T13:27:42.793373Z","iopub.execute_input":"2024-08-02T13:27:42.793696Z","iopub.status.idle":"2024-08-02T13:27:42.808612Z","shell.execute_reply.started":"2024-08-02T13:27:42.793661Z","shell.execute_reply":"2024-08-02T13:27:42.807899Z"},"trusted":true},"execution_count":155,"outputs":[]},{"cell_type":"code","source":"# Instantiate the model\nmodel = YOLOv3(NumClasses=NumClasses).to(DEVICE)\n\n# Compile the model\noptimizer = torch.optim.Adam(\n    model.parameters(), lr=RateOfLearning\n)\nloss_fn = YoloLoss()\n\n# Scaler\nscaler = torch.cuda.amp.GradScaler()\n\n# Train-Test Loader\ntrain_loader, test_loader = get_loaders(\n    train_csv_path='/kaggle/input/pascalvoc-yolo/test.csv', test_csv_path='/kaggle/input/pascalvoc-yolo/test.csv'\n)\n\n# Anchors\nscaled_anchors = (\n    torch.tensor(ANCHORS) * torch.tensor([13,26,52]).unsqueeze(1).unsqueeze(1).repeat(1,3,2)\n).to(DEVICE)","metadata":{"papermill":{"duration":3.599173,"end_time":"2023-12-19T17:28:52.355790","exception":false,"start_time":"2023-12-19T17:28:48.756617","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-08-02T13:27:42.809601Z","iopub.execute_input":"2024-08-02T13:27:42.809849Z","iopub.status.idle":"2024-08-02T13:27:43.327279Z","shell.execute_reply.started":"2024-08-02T13:27:42.809826Z","shell.execute_reply":"2024-08-02T13:27:43.326466Z"},"trusted":true},"execution_count":156,"outputs":[]},{"cell_type":"markdown","source":"# Training","metadata":{"id":"--AS2dslvM-D","papermill":{"duration":0.012926,"end_time":"2023-12-19T17:28:48.743475","exception":false,"start_time":"2023-12-19T17:28:48.730549","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Save test loader to a file\ntorch.save(test_loader, '/kaggle/working/test_loader.pth')","metadata":{"papermill":{"duration":0.032205,"end_time":"2023-12-19T17:28:52.401408","exception":false,"start_time":"2023-12-19T17:28:52.369203","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-08-02T13:27:43.328357Z","iopub.execute_input":"2024-08-02T13:27:43.328609Z","iopub.status.idle":"2024-08-02T13:27:43.342867Z","shell.execute_reply.started":"2024-08-02T13:27:43.328586Z","shell.execute_reply":"2024-08-02T13:27:43.341905Z"},"trusted":true},"execution_count":157,"outputs":[]},{"cell_type":"code","source":"import torch.optim as optim\n\nfrom tqdm import tqdm\nimport time\n\nhistory_loss = [] # To plot the epoch vs. loss\n\nfor epoch in tqdm(range(EpochsNo), desc=\"Epochs\"):\n  model.train()\n\n  losses = []\n\n  start_time = time.time() # Start time of the epoch\n\n  for batch_idx, (x,y) in enumerate(train_loader):\n    x = x.to(DEVICE)\n    y0, y1, y2 = (y[0].to(DEVICE),\n                  y[1].to(DEVICE),\n                  y[2].to(DEVICE))\n\n    # context manager is used in PyTorch to automatically handle mixed-precision computations on CUDA-enabled GPUs\n    with torch.cuda.amp.autocast():\n      out = model(x)\n      loss = (\n          loss_fn(out[0], y0, scaled_anchors[0])\n          + loss_fn(out[1], y1, scaled_anchors[1])\n          + loss_fn(out[2], y2, scaled_anchors[2])\n      )\n\n    losses.append(loss.item())\n    \n    optimizer.zero_grad()\n    scaler.scale(loss).backward()\n    scaler.step(optimizer)\n    scaler.update()\n\n  end_time = time.time()  # End time of the epoch\n  epoch_duration = end_time - start_time  # Duration of the epoch\n    \n  history_loss.append(sum(losses)/len(losses))\n\n  if (epoch+1) % 10 == 0:\n    # Print the epoch duration\n    tqdm.write(f\"Epoch {epoch+1} completed in {epoch_duration:.2f} seconds\")\n\n    # Print the loss and accuracy for training and validation data\n    print(f\"Epoch [{epoch+1}/{EpochsNo}], \"\n          f\"Loss: {sum(losses)/len(losses):.4f}\")\n\n    # save the model after every 10 epoch\n    torch.save(model.state_dict(), f'/kaggle/working/Yolov3_epoch{epoch+1}.pth')\n\n","metadata":{"id":"QxkC5a_lFOvA","outputId":"cb8c11e8-e6ba-42b5-ff27-d580e23ab481","papermill":{"duration":11747.786746,"end_time":"2023-12-19T20:44:40.200757","exception":false,"start_time":"2023-12-19T17:28:52.414011","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-08-02T13:27:43.343890Z","iopub.execute_input":"2024-08-02T13:27:43.344193Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"Epochs:   0%|          | 0/80 [00:00<?, ?it/s]","output_type":"stream"}]},{"cell_type":"code","source":"model.eval()\nx, y = next(iter(test_loader))\nx = x.float().to(DEVICE)\n\nwith torch.no_grad():\n    out = model(x)\n    boxx = [[] for _ in range(x.shape[0])]\n    batch_size, A, sp, _, _ = out[0].shape\n    anchor = torch.tensor([*ANCHORS[0]]).to(DEVICE) * sp\n    boxes_scale_i = cells_to_boxx(\n        out[0], anchor, sp=sp, is_preds=True\n    )\n    for idx, (box) in enumerate(boxes_scale_i):\n        boxx[idx] += box\n\n    for i in range(batch_size):\n        nms_boxes = non_max_suppression(\n            boxx[i], iou_threshold=0.5, threshold=0.6, box_format=\"midpoint\",\n        )\n        plot_image(x[i].permute(1,2,0).detach().cpu(), nms_boxes)","metadata":{"papermill":{"duration":10.470574,"end_time":"2023-12-19T20:44:51.103637","exception":false,"start_time":"2023-12-19T20:44:40.633063","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]}]}